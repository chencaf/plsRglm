<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Partial least squares Regression models with leave one out cross validation — plsR • plsRglm</title>

<!-- jquery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>
<!-- Bootstrap -->

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha256-916EbMg70RQy9LHiGkXzG8hSg9EdNy97GazNG/aiY1w=" crossorigin="anonymous" />
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script>

<!-- sticky kit -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script>



<meta property="og:title" content="Partial least squares Regression models with leave one out cross validation — plsR" />

<meta property="og:description" content="This function implements Partial least squares Regression models with leave one out cross validation for complete or incomplete datasets." />
<meta name="twitter:card" content="summary" />



<!-- mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->


  </head>

  <body>
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">plsRglm</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">1.2.5</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
      
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/fbertran/plsRglm">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header>

<div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Partial least squares Regression models with leave one out cross validation</h1>
    
    <div class="hidden name"><code>plsR.Rd</code></div>
    </div>

    <div class="ref-description">
    
    <p>This function implements Partial least squares Regression models with leave one out cross validation for complete or incomplete datasets.</p>
    
    </div>

    <pre class="usage">plsR(x, &#8230;)
# S3 method for default
plsRmodel(dataY, dataX, nt = 2, limQ2set = 0.0975, 
dataPredictY = dataX, modele = "pls", family = NULL, typeVC = "none", 
EstimXNA = FALSE, scaleX = TRUE, scaleY = NULL, pvals.expli = FALSE, 
alpha.pvals.expli = 0.05, MClassed = FALSE, tol_Xi = 10^(-12), weights,
sparse = FALSE, sparseStop = TRUE, naive = FALSE,verbose=TRUE)
# S3 method for formula
plsRmodel(formula, data, nt = 2, limQ2set = 0.0975,
dataPredictY, modele = "pls", family = NULL, typeVC = "none",
EstimXNA = FALSE, scaleX = TRUE, scaleY = NULL, pvals.expli = FALSE, 
alpha.pvals.expli = 0.05, MClassed = FALSE, tol_Xi = 10^(-12), weights,
subset, contrasts = NULL, sparse = FALSE, sparseStop = TRUE, naive = FALSE,
verbose=TRUE)
PLS_lm(dataY, dataX, nt = 2, limQ2set = 0.0975, dataPredictY = dataX, 
modele = "pls", family = NULL, typeVC = "none", EstimXNA = FALSE, 
scaleX = TRUE, scaleY = NULL, pvals.expli = FALSE, 
alpha.pvals.expli = 0.05, MClassed = FALSE, tol_Xi = 10^(-12),
weights,sparse=FALSE,sparseStop=FALSE,naive=FALSE,verbose=TRUE)
PLS_lm_formula(formula,data=NULL,nt=2,limQ2set=.0975,dataPredictY=dataX,
modele="pls",family=NULL,typeVC="none",EstimXNA=FALSE,scaleX=TRUE,
scaleY=NULL,pvals.expli=FALSE,alpha.pvals.expli=.05,MClassed=FALSE,
tol_Xi=10^(-12),weights,subset,contrasts=NULL,sparse=FALSE,
sparseStop=FALSE,naive=FALSE,verbose=TRUE)</pre>
    
    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a>Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>x</th>
      <td><p>a formula or a response (training) dataset</p></td>
    </tr>
    <tr>
      <th>dataY</th>
      <td><p>response (training) dataset</p></td>
    </tr>
    <tr>
      <th>dataX</th>
      <td><p>predictor(s) (training) dataset</p></td>
    </tr>
    <tr>
      <th>formula</th>
      <td><p>an object of class "<code><a href='https://www.rdocumentation.org/packages/stats/topics/formula'>formula</a></code>" (or one that can be coerced to that class): a symbolic description of the model to be fitted. The details of model specification are given under 'Details'.</p></td>
    </tr>
    <tr>
      <th>data</th>
      <td><p>an optional data frame, list or environment (or object coercible by <code><a href='https://www.rdocumentation.org/packages/base/topics/as.data.frame'>as.data.frame</a></code> to a data frame) containing the variables in the model. If not found in <code>data</code>, the variables are taken from <code><a href='https://www.rdocumentation.org/packages/base/topics/environment'>environment(formula)</a></code>, typically the environment from which <code>plsR</code> is called.</p></td>
    </tr>
    <tr>
      <th>nt</th>
      <td><p>number of components to be extracted</p></td>
    </tr>
    <tr>
      <th>limQ2set</th>
      <td><p>limit value for the Q2</p></td>
    </tr>
    <tr>
      <th>dataPredictY</th>
      <td><p>predictor(s) (testing) dataset</p></td>
    </tr>
    <tr>
      <th>modele</th>
      <td><p>name of the PLS model to be fitted, only (<code>"pls"</code> available for this fonction.</p></td>
    </tr>
    <tr>
      <th>family</th>
      <td><p>for the present moment the family argument is ignored and set thanks to the value of modele.</p></td>
    </tr>
    <tr>
      <th>typeVC</th>
      <td><p>type of leave one out cross validation. Several procedures are available. If cross validation is required, one needs to selects the way of predicting the response for left out observations. For complete rows, without any missing value, there are two different ways of computing these predictions. As a consequence, for mixed datasets, with complete and incomplete rows, there are two ways of computing prediction : either predicts any row as if there were missing values in it (<code>missingdata</code>) or selects the prediction method accordingly to the completeness of the row (<code>adaptative</code>).</p><dl class='dl-horizontal'>
      <dt><code>none</code></dt><dd><p>no cross validation</p></dd>
      <dt><code>standard</code></dt><dd><p>as in SIMCA for datasets without any missing value. For datasets with any missing value, it is the as using <code>missingdata</code></p></dd>
      <dt><code>missingdata</code></dt><dd><p>all values predicted as those with missing values for datasets with any missing values</p></dd>
      <dt><code>adaptative</code></dt><dd><p>predict a response value for an x with any missing value as those with missing values and for an x without any missing value as those without missing values.</p></dd>
      </dl><p></p></td>
    </tr>
    <tr>
      <th>EstimXNA</th>
      <td><p>only for <code>modele="pls"</code>. Set whether the missing X values have to be estimated.</p></td>
    </tr>
    <tr>
      <th>scaleX</th>
      <td><p>scale the predictor(s) : must be set to TRUE for <code>modele="pls"</code> and should be for glms pls.</p></td>
    </tr>
    <tr>
      <th>scaleY</th>
      <td><p>scale the response : Yes/No. Ignored since non always possible for glm responses.</p></td>
    </tr>
    <tr>
      <th>pvals.expli</th>
      <td><p>should individual p-values be reported to tune model selection ?</p></td>
    </tr>
    <tr>
      <th>alpha.pvals.expli</th>
      <td><p>level of significance for predictors when pvals.expli=TRUE</p></td>
    </tr>
    <tr>
      <th>MClassed</th>
      <td><p>number of missclassified cases, should only be used for binary responses</p></td>
    </tr>
    <tr>
      <th>tol_Xi</th>
      <td><p>minimal value for Norm2(Xi) and \(\mathrm{det}(pp' \times pp)\) if there is any missing value in the <code>dataX</code>. It defaults to \(10^{-12}\)</p></td>
    </tr>
    <tr>
      <th>weights</th>
      <td><p>an optional vector of 'prior weights' to be used in the fitting process. Should be <code>NULL</code> or a numeric vector.</p></td>
    </tr>
    <tr>
      <th>subset</th>
      <td><p>an optional vector specifying a subset of observations to be used in the fitting process.</p></td>
    </tr>
    <tr>
      <th>contrasts</th>
      <td><p>an optional list. See the <code>contrasts.arg</code> of <code>model.matrix.default</code>.</p></td>
    </tr>
    <tr>
      <th>sparse</th>
      <td><p>should the coefficients of non-significant predictors (&lt;<code>alpha.pvals.expli</code>) be set to 0</p></td>
    </tr>
    <tr>
      <th>sparseStop</th>
      <td><p>should component extraction stop when no significant predictors (&lt;<code>alpha.pvals.expli</code>) are found</p></td>
    </tr>
    <tr>
      <th>naive</th>
      <td><p>Use the naive estimates for the Degrees of Freedom in plsR? Default is <code>FALSE</code>.</p></td>
    </tr>
    <tr>
      <th>verbose</th>
      <td><p>should info messages be displayed ?</p></td>
    </tr>
    <tr>
      <th>&#8230;</th>
      <td><p>arguments to pass to <code>plsRmodel.default</code> or to <code>plsRmodel.formula</code></p></td>
    </tr>
    </table>
    
    <h2 class="hasAnchor" id="details"><a class="anchor" href="#details"></a>Details</h2>

    <p>There are several ways to deal with missing values that leads to different computations of leave one out cross validation criteria.</p>
<p>A typical predictor has the form response ~ terms where response is the (numeric) response vector and terms is a series of terms which specifies a linear predictor for response. A terms specification of the form first + second indicates all the terms in first together with all the terms in second with any duplicates removed.</p>
<p>A specification of the form first:second indicates the the set of terms obtained by taking the interactions of all terms in first with all terms in second. The specification first*second indicates the cross of first and second. This is the same as first + second + first:second.</p>
<p>The terms in the formula will be re-ordered so that main effects come first, followed by the interactions, all second-order, all third-order and so on: to avoid this pass a terms object as the formula.</p>
<p>Non-NULL weights can be used to indicate that different observations have different dispersions (with the values in weights being inversely proportional to the dispersions); or equivalently, when the elements of weights are positive integers w_i, that each response y_i is the mean of w_i unit-weight observations.</p>
<p>The default estimator for Degrees of Freedom is the Kramer and Sugiyama's one. Information criteria are computed accordingly to these estimations. Naive Degrees of Freedom and Information Criteria are also provided for comparison purposes. For more details, see N. Kraemer and M. Sugiyama. (2011). The Degrees of Freedom of Partial Least Squares Regression. <em>Journal of the American Statistical Association</em>, 106(494), 697-705, 2011.</p>
    
    <h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p></p>
<dt>nr</dt><dd><p>Number of observations</p></dd>
  <dt>nc</dt><dd><p>Number of predictors</p></dd>
  <dt>nt</dt><dd><p>Number of requested components</p></dd>
  <dt>ww</dt><dd><p>raw weights (before L2-normalization)</p></dd>
  <dt>wwnorm</dt><dd><p>L2 normed weights (to be used with deflated matrices of predictor variables)</p></dd>
  <dt>wwetoile</dt><dd><p>modified weights (to be used with original matrix of predictor variables)</p></dd>
  <dt>tt</dt><dd><p>PLS components</p></dd>
  <dt>pp</dt><dd><p>loadings of the predictor variables</p></dd>
  <dt>CoeffC</dt><dd><p>coefficients of the PLS components</p></dd>
  <dt>uscores</dt><dd><p>scores of the response variable</p></dd>
  <dt>YChapeau</dt><dd><p>predicted response values for the dataX set</p></dd>
  <dt>residYChapeau</dt><dd><p>residuals of the deflated response on the standardized scale</p></dd>
  <dt>RepY</dt><dd><p>scaled response vector</p></dd>
  <dt>na.miss.Y</dt><dd><p>is there any NA value in the response vector</p></dd>
  <dt>YNA</dt><dd><p>indicatrix vector of missing values in RepY</p></dd>
  <dt>residY</dt><dd><p>deflated scaled response vector</p></dd>
  <dt>ExpliX</dt><dd><p>scaled matrix of predictors</p></dd>
  <dt>na.miss.X</dt><dd><p>is there any NA value in the predictor matrix</p></dd>
  <dt>XXNA</dt><dd><p>indicator of non-NA values in the predictor matrix</p></dd>
  <dt>residXX</dt><dd><p>deflated predictor matrix</p></dd>
  <dt>PredictY</dt><dd><p>response values with NA replaced with 0</p></dd>
  <dt>press.ind</dt><dd><p>individual PRESS value for each observation (scaled scale)</p></dd>
  <dt>press.tot</dt><dd><p>total PRESS value for all observations (scaled scale)</p></dd>
  <dt>family</dt><dd><p>glm family used to fit PLSGLR model</p></dd>
  <dt>ttPredictY</dt><dd><p>PLS components for the dataset on which prediction was requested</p></dd>
  <dt>typeVC</dt><dd><p>type of leave one out cross-validation used</p></dd>
  <dt>dataX</dt><dd><p>predictor values</p></dd>
  <dt>dataY</dt><dd><p>response values</p></dd>
  <dt>computed_nt</dt><dd><p>number of components that were computed</p></dd>
  <dt>CoeffCFull</dt><dd><p>matrix of the coefficients of the predictors</p></dd>
  <dt>CoeffConstante</dt><dd><p>value of the intercept (scaled scale)</p></dd>
  <dt>Std.Coeffs</dt><dd><p>Vector of standardized regression coefficients</p></dd>
  <dt>press.ind2</dt><dd><p>individual PRESS value for each observation (original scale)</p></dd>
  <dt>RSSresidY</dt><dd><p>residual sum of squares (scaled scale)</p></dd>
  <dt>Coeffs</dt><dd><p>Vector of regression coefficients (used with the original data scale)</p></dd>
  <dt>Yresidus</dt><dd><p>residuals of the PLS model</p></dd>
  <dt>RSS</dt><dd><p>residual sum of squares (original scale)</p></dd>
  <dt>residusY</dt><dd><p>residuals of the deflated response on the standardized scale</p></dd>
  <dt>AIC.std</dt><dd><p>AIC.std vs number of components (AIC computed for the standardized model</p></dd>
  <dt>AIC</dt><dd><p>AIC vs number of components</p></dd>
  <dt>optional</dt><dd><p>If the response is assumed to be binary:<br />
        i.e. <code>MClassed=TRUE</code>.    
  <dl class='dl-horizontal'>
  <dt><code>MissClassed</code></dt><dd><p>Number of miss classed results</p></dd>
  <dt><code>Probs</code></dt><dd><p>"Probability" predicted by the model. These are not true probabilities since they may lay outside of [0,1]</p></dd>
  <dt><code>Probs.trc</code></dt><dd><p>Probability predicted by the model and constrained to belong to [0,1]</p></dd>
  </dl></p></dd>
  <dt>ttPredictFittedMissingY</dt><dd><p>Description of 'comp2'</p></dd>
  <dt>optional</dt><dd><p>If cross validation was requested:<br />
        i.e. <code>typeVC="standard"</code>, <code>typeVC="missingdata"</code> or <code>typeVC="adaptative"</code>.
  <dl class='dl-horizontal'>
  <dt><code>R2residY</code></dt><dd><p>R2 coefficient value on the standardized scale</p></dd>
  <dt><code>R2</code></dt><dd><p>R2 coefficient value on the original scale</p></dd>
  <dt><code>press.tot2</code></dt><dd><p>total PRESS value for all observations (original scale)</p></dd>
  <dt><code>Q2</code></dt><dd><p>Q2 value (standardized scale)</p></dd>
  <dt><code>limQ2</code></dt><dd><p>limit of the Q2 value</p></dd>
  <dt><code>Q2_2</code></dt><dd><p>Q2 value (original scale)</p></dd>
  <dt><code>Q2cum</code></dt><dd><p>cumulated Q2 (standardized scale)</p></dd>
  <dt><code>Q2cum_2</code></dt><dd><p>cumulated Q2 (original scale)</p></dd>
  </dl></p></dd>
  <dt>InfCrit</dt><dd><p>table of Information Criteria</p></dd>
  <dt>Std.ValsPredictY</dt><dd><p>predicted response values for supplementary dataset (standardized scale)</p></dd>
  <dt>ValsPredictY</dt><dd><p>predicted response values for supplementary dataset (original scale)</p></dd>
  <dt>Std.XChapeau</dt><dd><p>estimated values for missing values in the predictor matrix (standardized scale)</p></dd>
  <dt>XXwotNA</dt><dd><p>predictor matrix with missing values replaced with 0</p></dd>

    
    <h2 class="hasAnchor" id="references"><a class="anchor" href="#references"></a>References</h2>

    <p>Nicolas Meyer, Myriam Maumy-Bertrand et Frederic Bertrand (2010). Comparing the linear and the logistic PLS regression with qualitative predictors: application to allelotyping data. <em>Journal de la Societe Francaise de Statistique</em>, 151(2), pages 1-18.
<a href='http://publications-sfds.math.cnrs.fr/index.php/J-SFdS/article/view/47'>http://publications-sfds.math.cnrs.fr/index.php/J-SFdS/article/view/47</a></p>
    
    <h2 class="hasAnchor" id="note"><a class="anchor" href="#note"></a>Note</h2>

    <p>Use <code><a href='cv.plsR.html'>cv.plsR</a></code> to cross-validate the plsRglm models and <code><a href='bootpls.html'>bootpls</a></code> to bootstrap them.</p>
    
    <h2 class="hasAnchor" id="see-also"><a class="anchor" href="#see-also"></a>See also</h2>

    <div class='dont-index'><p>See also <code><a href='plsRglm.html'>plsRglm</a></code> to fit PLSGLR models.</p></div>
    

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><div class='input'><span class='fu'><a href='https://www.rdocumentation.org/packages/utils/topics/data'>data</a></span>(<span class='no'>Cornell</span>)
<span class='no'>XCornell</span><span class='kw'>&lt;-</span><span class='no'>Cornell</span>[,<span class='fl'>1</span>:<span class='fl'>7</span>]
<span class='no'>yCornell</span><span class='kw'>&lt;-</span><span class='no'>Cornell</span>[,<span class='fl'>8</span>]

<span class='co'>#maximum 6 components could be extracted from this dataset</span>
<span class='co'>#trying 10 to trigger automatic stopping criterion</span>
<span class='no'>modpls10</span><span class='kw'>&lt;-</span><span class='fu'>plsR</span>(<span class='no'>yCornell</span>,<span class='no'>XCornell</span>,<span class='fl'>10</span>)</div><div class='output co'>#&gt; ____************************************************____
#&gt; ____Component____ 1 ____
#&gt; ____Component____ 2 ____
#&gt; ____Component____ 3 ____
#&gt; ____Component____ 4 ____
#&gt; ____Component____ 5 ____
#&gt; ____Component____ 6 ____
#&gt; Warning : 1 2 3 4 5 6 7 &lt; 10^{-12}
#&gt; Warning only 6 components could thus be extracted
#&gt; ____Predicting X without NA neither in X nor in Y____
#&gt; ****________________________________________________****
#&gt; </div><div class='input'><span class='no'>modpls10</span></div><div class='output co'>#&gt; Number of required components:
#&gt; [1] 10
#&gt; Number of successfully computed components:
#&gt; [1] 6
#&gt; Coefficients:
#&gt;                  [,1]
#&gt; Intercept  88.7107982
#&gt; X1        -54.3905712
#&gt; X2         -2.7879678
#&gt; X3         52.5411315
#&gt; X4        -11.5306977
#&gt; X5         -0.9605822
#&gt; X6         11.5900307
#&gt; X7         28.2104803
#&gt; Information criteria and Fit statistics:
#&gt;                AIC      RSS_Y      R2_Y R2_residY  RSS_residY    AIC.std
#&gt; Nb_Comp_0 82.01205 467.796667        NA        NA 11.00000000  37.010388
#&gt; Nb_Comp_1 53.15173  35.742486 0.9235940 0.9235940  0.84046633   8.150064
#&gt; Nb_Comp_2 41.08283  11.066606 0.9763431 0.9763431  0.26022559  -3.918831
#&gt; Nb_Comp_3 32.06411   4.418081 0.9905556 0.9905556  0.10388893 -12.937550
#&gt; Nb_Comp_4 33.76477   4.309235 0.9907882 0.9907882  0.10132947 -11.236891
#&gt; Nb_Comp_5 33.34373   3.521924 0.9924713 0.9924713  0.08281624 -11.657929
#&gt; Nb_Comp_6 35.25533   3.496074 0.9925265 0.9925265  0.08220840  -9.746328
#&gt;            DoF.dof sigmahat.dof    AIC.dof    BIC.dof GMDL.dof DoF.naive
#&gt; Nb_Comp_0 1.000000    6.5212706 46.0708838 47.7893514 27.59461         1
#&gt; Nb_Comp_1 2.740749    1.8665281  4.5699686  4.9558156 21.34020         2
#&gt; Nb_Comp_2 5.085967    1.1825195  2.1075461  2.3949331 27.40202         3
#&gt; Nb_Comp_3 5.121086    0.7488308  0.8467795  0.9628191 24.40842         4
#&gt; Nb_Comp_4 5.103312    0.7387162  0.8232505  0.9357846 24.23105         5
#&gt; Nb_Comp_5 6.006316    0.7096382  0.7976101  0.9198348 28.21184         6
#&gt; Nb_Comp_6 7.000002    0.7633343  0.9711322  1.1359501 33.18348         7
#&gt;           sigmahat.naive  AIC.naive  BIC.naive GMDL.naive
#&gt; Nb_Comp_0      6.5212706 46.0708838 47.7893514   27.59461
#&gt; Nb_Comp_1      1.8905683  4.1699567  4.4588195   18.37545
#&gt; Nb_Comp_2      1.1088836  1.5370286  1.6860917   17.71117
#&gt; Nb_Comp_3      0.7431421  0.7363469  0.8256118   19.01033
#&gt; Nb_Comp_4      0.7846050  0.8721072  0.9964867   24.16510
#&gt; Nb_Comp_5      0.7661509  0.8804809  1.0227979   28.64206
#&gt; Nb_Comp_6      0.8361907  1.1070902  1.3048716   33.63927</div><div class='input'>
<span class='co'>#With iterated leave one out CV PRESS</span>
<span class='no'>modpls6cv</span><span class='kw'>&lt;-</span><span class='fu'>plsR</span>(<span class='no'>Y</span>~<span class='no'>.</span>,<span class='kw'>data</span><span class='kw'>=</span><span class='no'>Cornell</span>,<span class='fl'>6</span>,<span class='kw'>typeVC</span><span class='kw'>=</span><span class='st'>"standard"</span>)</div><div class='output co'>#&gt; ____************************************************____
#&gt; ____TypeVC____ standard ____
#&gt; ____Component____ 1 ____
#&gt; ____Component____ 2 ____
#&gt; ____Component____ 3 ____
#&gt; ____Component____ 4 ____
#&gt; ____Component____ 5 ____
#&gt; ____Component____ 6 ____
#&gt; ____Predicting X without NA neither in X nor in Y____
#&gt; ****________________________________________________****
#&gt; </div><div class='input'><span class='no'>modpls6cv</span></div><div class='output co'>#&gt; Number of required components:
#&gt; [1] 6
#&gt; Number of successfully computed components:
#&gt; [1] 6
#&gt; Coefficients:
#&gt;                  [,1]
#&gt; Intercept  88.7107982
#&gt; X1        -54.3905712
#&gt; X2         -2.7879678
#&gt; X3         52.5411315
#&gt; X4        -11.5306977
#&gt; X5         -0.9605822
#&gt; X6         11.5900307
#&gt; X7         28.2104803
#&gt; Leave one out cross validated PRESS, Information criteria and Fit statistics:
#&gt;                AIC   Q2cum_Y LimQ2_Y        Q2_Y   PRESS_Y      RSS_Y      R2_Y
#&gt; Nb_Comp_0 82.01205        NA      NA          NA        NA 467.796667        NA
#&gt; Nb_Comp_1 53.15173 0.8966556  0.0975  0.89665563 48.344150  35.742486 0.9235940
#&gt; Nb_Comp_2 41.08283 0.9175426  0.0975  0.20210989 28.518576  11.066606 0.9763431
#&gt; Nb_Comp_3 32.06411 0.9399676  0.0975  0.27195907  8.056942   4.418081 0.9905556
#&gt; Nb_Comp_4 33.76477 0.9197009  0.0975 -0.33759604  5.909608   4.309235 0.9907882
#&gt; Nb_Comp_5 33.34373 0.9281373  0.0975  0.10506161  3.856500   3.521924 0.9924713
#&gt; Nb_Comp_6 35.25533 0.9232562  0.0975 -0.06792167  3.761138   3.496074 0.9925265
#&gt;           R2_residY  RSS_residY PRESS_residY   Q2_residY  LimQ2 Q2cum_residY
#&gt; Nb_Comp_0        NA 11.00000000           NA          NA     NA           NA
#&gt; Nb_Comp_1 0.9235940  0.84046633   1.13678803  0.89665563 0.0975    0.8966556
#&gt; Nb_Comp_2 0.9763431  0.26022559   0.67059977  0.20210989 0.0975    0.9175426
#&gt; Nb_Comp_3 0.9905556  0.10388893   0.18945488  0.27195907 0.0975    0.9399676
#&gt; Nb_Comp_4 0.9907882  0.10132947   0.13896142 -0.33759604 0.0975    0.9197009
#&gt; Nb_Comp_5 0.9924713  0.08281624   0.09068364  0.10506161 0.0975    0.9281373
#&gt; Nb_Comp_6 0.9925265  0.08220840   0.08844125 -0.06792167 0.0975    0.9232562
#&gt;              AIC.std  DoF.dof sigmahat.dof    AIC.dof    BIC.dof GMDL.dof
#&gt; Nb_Comp_0  37.010388 1.000000    6.5212706 46.0708838 47.7893514 27.59461
#&gt; Nb_Comp_1   8.150064 2.740749    1.8665281  4.5699686  4.9558156 21.34020
#&gt; Nb_Comp_2  -3.918831 5.085967    1.1825195  2.1075461  2.3949331 27.40202
#&gt; Nb_Comp_3 -12.937550 5.121086    0.7488308  0.8467795  0.9628191 24.40842
#&gt; Nb_Comp_4 -11.236891 5.103312    0.7387162  0.8232505  0.9357846 24.23105
#&gt; Nb_Comp_5 -11.657929 6.006316    0.7096382  0.7976101  0.9198348 28.21184
#&gt; Nb_Comp_6  -9.746328 7.000002    0.7633343  0.9711322  1.1359501 33.18348
#&gt;           DoF.naive sigmahat.naive  AIC.naive  BIC.naive GMDL.naive
#&gt; Nb_Comp_0         1      6.5212706 46.0708838 47.7893514   27.59461
#&gt; Nb_Comp_1         2      1.8905683  4.1699567  4.4588195   18.37545
#&gt; Nb_Comp_2         3      1.1088836  1.5370286  1.6860917   17.71117
#&gt; Nb_Comp_3         4      0.7431421  0.7363469  0.8256118   19.01033
#&gt; Nb_Comp_4         5      0.7846050  0.8721072  0.9964867   24.16510
#&gt; Nb_Comp_5         6      0.7661509  0.8804809  1.0227979   28.64206
#&gt; Nb_Comp_6         7      0.8361907  1.1070902  1.3048716   33.63927</div><div class='input'><span class='no'>cv.modpls</span><span class='kw'>&lt;-</span><span class='fu'><a href='cv.plsR.html'>cv.plsR</a></span>(<span class='no'>Y</span>~<span class='no'>.</span>,<span class='kw'>data</span><span class='kw'>=</span><span class='no'>Cornell</span>,<span class='fl'>6</span>,<span class='kw'>NK</span><span class='kw'>=</span><span class='fl'>100</span>, <span class='kw'>verbose</span><span class='kw'>=</span><span class='fl'>FALSE</span>)
<span class='no'>res.cv.modpls</span><span class='kw'>&lt;-</span><span class='fu'><a href='cvtable.html'>cvtable</a></span>(<span class='fu'><a href='https://www.rdocumentation.org/packages/base/topics/summary'>summary</a></span>(<span class='no'>cv.modpls</span>))</div><div class='output co'>#&gt; ____************************************************____
#&gt; ____Component____ 1 ____
#&gt; ____Component____ 2 ____
#&gt; ____Component____ 3 ____
#&gt; ____Component____ 4 ____
#&gt; ____Component____ 5 ____
#&gt; ____Component____ 6 ____
#&gt; ____Predicting X without NA neither in X nor in Y____
#&gt; ****________________________________________________****
#&gt; 
#&gt; 
#&gt; NK: 1,  2,  3,  4,  5,  6,  7,  8,  9,  10
#&gt; NK: 11,  12,  13,  14,  15,  16,  17,  18,  19,  20
#&gt; NK: 21,  22,  23,  24,  25,  26,  27,  28,  29,  30
#&gt; NK: 31,  32,  33,  34,  35,  36,  37,  38,  39,  40
#&gt; NK: 41,  42,  43,  44,  45,  46,  47,  48,  49,  50
#&gt; NK: 51,  52,  53,  54,  55,  56,  57,  58,  59,  60
#&gt; NK: 61,  62,  63,  64,  65,  66,  67,  68,  69,  70
#&gt; NK: 71,  72,  73,  74,  75,  76,  77,  78,  79,  80
#&gt; NK: 81,  82,  83,  84,  85,  86,  87,  88,  89,  90
#&gt; NK: 91,  92,  93,  94,  95,  96,  97,  98,  99,  100
#&gt; 
#&gt; CV Q2 criterion:
#&gt;  0  1  2 
#&gt;  0 88 12 
#&gt; 
#&gt; CV Press criterion:
#&gt;  1  2  3  4  5 
#&gt;  0  1 33 46 20 </div><div class='input'><span class='fu'><a href='https://www.rdocumentation.org/packages/graphics/topics/plot'>plot</a></span>(<span class='no'>res.cv.modpls</span>)</div><div class='img'><img src='plsR-1.png' alt='' width='700' height='433' /></div><div class='input'>
<span class='fu'><a href='https://www.rdocumentation.org/packages/base/topics/rm'>rm</a></span>(<span class='kw'>list</span><span class='kw'>=</span><span class='fu'><a href='https://www.rdocumentation.org/packages/base/topics/c'>c</a></span>(<span class='st'>"XCornell"</span>,<span class='st'>"yCornell"</span>,<span class='st'>"modpls10"</span>,<span class='st'>"modpls6cv"</span>))</div><div class='input'><span class='co'>#A binary response example</span>
<span class='fu'><a href='https://www.rdocumentation.org/packages/utils/topics/data'>data</a></span>(<span class='no'>aze_compl</span>)
<span class='no'>Xaze_compl</span><span class='kw'>&lt;-</span><span class='no'>aze_compl</span>[,<span class='fl'>2</span>:<span class='fl'>34</span>]
<span class='no'>yaze_compl</span><span class='kw'>&lt;-</span><span class='no'>aze_compl</span>$<span class='no'>y</span>
<span class='no'>modpls.aze</span> <span class='kw'>&lt;-</span> <span class='fu'>plsR</span>(<span class='no'>yaze_compl</span>,<span class='no'>Xaze_compl</span>,<span class='fl'>10</span>,<span class='kw'>MClassed</span><span class='kw'>=</span><span class='fl'>TRUE</span>,<span class='kw'>typeVC</span><span class='kw'>=</span><span class='st'>"standard"</span>)</div><div class='output co'>#&gt; ____************************************************____
#&gt; ____TypeVC____ standard ____
#&gt; ____Component____ 1 ____
#&gt; ____Component____ 2 ____
#&gt; ____Component____ 3 ____
#&gt; ____Component____ 4 ____
#&gt; ____Component____ 5 ____
#&gt; ____Component____ 6 ____
#&gt; ____Component____ 7 ____
#&gt; ____Component____ 8 ____
#&gt; ____Component____ 9 ____
#&gt; ____Component____ 10 ____
#&gt; ____Predicting X without NA neither in X nor in Y____
#&gt; ****________________________________________________****
#&gt; </div><div class='input'><span class='no'>modpls.aze</span></div><div class='output co'>#&gt; Number of required components:
#&gt; [1] 10
#&gt; Number of successfully computed components:
#&gt; [1] 10
#&gt; Coefficients:
#&gt;                   [,1]
#&gt; Intercept  0.308019808
#&gt; D2S138    -0.131218617
#&gt; D18S61     0.450219840
#&gt; D16S422   -0.183848373
#&gt; D17S794    0.269084083
#&gt; D6S264     0.105061098
#&gt; D14S65    -0.052837918
#&gt; D18S53     0.008489326
#&gt; D17S790   -0.213122117
#&gt; D1S225     0.046277290
#&gt; D3S1282   -0.095666162
#&gt; D9S179     0.054547887
#&gt; D5S430    -0.126491043
#&gt; D8S283     0.106373432
#&gt; D11S916    0.111623381
#&gt; D2S159     0.056759714
#&gt; D16S408    0.010288859
#&gt; D5S346     0.233674850
#&gt; D10S191    0.010715856
#&gt; D13S173    0.074148740
#&gt; D6S275    -0.123145693
#&gt; D15S127    0.064566148
#&gt; D1S305     0.190500469
#&gt; D4S394    -0.142585807
#&gt; D20S107   -0.184483600
#&gt; D1S197    -0.284373695
#&gt; D1S207     0.186728597
#&gt; D10S192    0.195516079
#&gt; D3S1283   -0.096309755
#&gt; D4S414     0.017960975
#&gt; D8S264     0.121051206
#&gt; D22S928   -0.049091794
#&gt; TP53      -0.391965015
#&gt; D9S171    -0.012315197
#&gt; Leave one out cross validated PRESS, Information criteria and Fit statistics:
#&gt;                 AIC      Q2cum_Y LimQ2_Y        Q2_Y  PRESS_Y    RSS_Y
#&gt; Nb_Comp_0  154.6179           NA      NA          NA       NA 25.91346
#&gt; Nb_Comp_1  126.4083  -0.09840016  0.0975 -0.09840016 28.46335 19.38086
#&gt; Nb_Comp_2  119.3375  -0.19018163  0.0975 -0.08355923 21.00031 17.76209
#&gt; Nb_Comp_3  114.2313  -0.77332918  0.0975 -0.48996518 26.46489 16.58896
#&gt; Nb_Comp_4  112.3463  -1.64635954  0.0975 -0.49231150 24.75590 15.98071
#&gt; Nb_Comp_5  113.2362  -2.74242209  0.0975 -0.41417749 22.59955 15.81104
#&gt; Nb_Comp_6  114.7620  -4.46009228  0.0975 -0.45897286 23.06788 15.73910
#&gt; Nb_Comp_7  116.5264  -7.36664482  0.0975 -0.53232663 24.11744 15.70350
#&gt; Nb_Comp_8  118.4601 -11.80011367  0.0975 -0.52989806 24.02475 15.69348
#&gt; Nb_Comp_9  120.4452 -17.90787273  0.0975 -0.47716444 23.18185 15.69123
#&gt; Nb_Comp_10 122.4395 -26.50536212  0.0975 -0.45470421 22.82610 15.69037
#&gt;                 R2_Y MissClassed R2_residY RSS_residY PRESS_residY   Q2_residY
#&gt; Nb_Comp_0         NA          49        NA  103.00000           NA          NA
#&gt; Nb_Comp_1  0.2520929          27 0.2520929   77.03443    113.13522 -0.09840016
#&gt; Nb_Comp_2  0.3145613          25 0.3145613   70.60018     83.47137 -0.08355923
#&gt; Nb_Comp_3  0.3598323          27 0.3598323   65.93728    105.19181 -0.48996518
#&gt; Nb_Comp_4  0.3833049          23 0.3833049   63.51960     98.39895 -0.49231150
#&gt; Nb_Comp_5  0.3898523          22 0.3898523   62.84522     89.82798 -0.41417749
#&gt; Nb_Comp_6  0.3926285          21 0.3926285   62.55927     91.68947 -0.45897286
#&gt; Nb_Comp_7  0.3940024          20 0.3940024   62.41775     95.86123 -0.53232663
#&gt; Nb_Comp_8  0.3943888          20 0.3943888   62.37795     95.49280 -0.52989806
#&gt; Nb_Comp_9  0.3944758          19 0.3944758   62.36900     92.14249 -0.47716444
#&gt; Nb_Comp_10 0.3945088          19 0.3945088   62.36560     90.72844 -0.45470421
#&gt;             LimQ2 Q2cum_residY  AIC.std  DoF.dof sigmahat.dof   AIC.dof
#&gt; Nb_Comp_0      NA           NA 298.1344  1.00000    0.5015845 0.2540061
#&gt; Nb_Comp_1  0.0975  -0.09840016 269.9248 22.55372    0.4848429 0.2883114
#&gt; Nb_Comp_2  0.0975  -0.19018163 262.8540 27.31542    0.4781670 0.2908950
#&gt; Nb_Comp_3  0.0975  -0.77332918 257.7478 30.52370    0.4719550 0.2902572
#&gt; Nb_Comp_4  0.0975  -1.64635954 255.8628 34.00000    0.4744263 0.3008285
#&gt; Nb_Comp_5  0.0975  -2.74242209 256.7527 34.00000    0.4719012 0.2976347
#&gt; Nb_Comp_6  0.0975  -4.46009228 258.2785 34.00000    0.4708264 0.2962804
#&gt; Nb_Comp_7  0.0975  -7.36664482 260.0429 33.71066    0.4693382 0.2937976
#&gt; Nb_Comp_8  0.0975 -11.80011367 261.9766 34.00000    0.4701436 0.2954217
#&gt; Nb_Comp_9  0.0975 -17.90787273 263.9617 33.87284    0.4696894 0.2945815
#&gt; Nb_Comp_10 0.0975 -26.50536212 265.9560 34.00000    0.4700970 0.2953632
#&gt;              BIC.dof  GMDL.dof DoF.naive sigmahat.naive AIC.naive BIC.naive
#&gt; Nb_Comp_0  0.2604032 -67.17645         1      0.5015845 0.2540061 0.2604032
#&gt; Nb_Comp_1  0.4231184 -53.56607         2      0.4358996 0.1936625 0.2033251
#&gt; Nb_Comp_2  0.4496983 -52.42272         3      0.4193593 0.1809352 0.1943501
#&gt; Nb_Comp_3  0.4631316 -51.93343         4      0.4072955 0.1722700 0.1891422
#&gt; Nb_Comp_4  0.4954133 -50.37079         5      0.4017727 0.1691819 0.1897041
#&gt; Nb_Comp_5  0.4901536 -50.65724         6      0.4016679 0.1706451 0.1952588
#&gt; Nb_Comp_6  0.4879234 -50.78005         7      0.4028135 0.1731800 0.2020601
#&gt; Nb_Comp_7  0.4826103 -51.05525         8      0.4044479 0.1761610 0.2094352
#&gt; Nb_Comp_8  0.4865092 -50.85833         9      0.4064413 0.1794902 0.2172936
#&gt; Nb_Comp_9  0.4845867 -50.95616        10      0.4085682 0.1829787 0.2254232
#&gt; Nb_Comp_10 0.4864128 -50.86368        11      0.4107477 0.1865584 0.2337468
#&gt;            GMDL.naive
#&gt; Nb_Comp_0   -67.17645
#&gt; Nb_Comp_1   -79.67755
#&gt; Nb_Comp_2   -81.93501
#&gt; Nb_Comp_3   -83.31503
#&gt; Nb_Comp_4   -83.23369
#&gt; Nb_Comp_5   -81.93513
#&gt; Nb_Comp_6   -80.42345
#&gt; Nb_Comp_7   -78.87607
#&gt; Nb_Comp_8   -77.31942
#&gt; Nb_Comp_9   -75.80069
#&gt; Nb_Comp_10  -74.33325</div><div class='input'>
<span class='co'>#Direct access to not cross-validated values</span>
<span class='no'>modpls.aze</span>$<span class='no'>AIC</span></div><div class='output co'>#&gt;          [,1]     [,2]     [,3]     [,4]     [,5]     [,6]    [,7]     [,8]
#&gt; [1,] 154.6179 126.4083 119.3375 114.2313 112.3463 113.2362 114.762 116.5264
#&gt;          [,9]    [,10]    [,11]
#&gt; [1,] 118.4601 120.4452 122.4395</div><div class='input'><span class='no'>modpls.aze</span>$<span class='no'>AIC.std</span></div><div class='output co'>#&gt;          [,1]     [,2]    [,3]     [,4]     [,5]     [,6]     [,7]     [,8]
#&gt; [1,] 298.1344 269.9248 262.854 257.7478 255.8628 256.7527 258.2785 260.0429
#&gt;          [,9]    [,10]   [,11]
#&gt; [1,] 261.9766 263.9617 265.956</div><div class='input'><span class='no'>modpls.aze</span>$<span class='no'>MissClassed</span></div><div class='output co'>#&gt;      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11]
#&gt; [1,]   49   27   25   27   23   22   21   20   20    19    19</div><div class='input'>
<span class='co'>#Raw predicted values (not really probabily since not constrained in [0,1]</span>
<span class='no'>modpls.aze</span>$<span class='no'>Probs</span></div><div class='output co'>#&gt;          [,1]        [,2]        [,3]        [,4]        [,5]        [,6]
#&gt; 1   0.4711538  0.46105744  0.63458141  0.67961627  0.69452246  0.64534767
#&gt; 2   0.4711538  0.26911816  0.26581497  0.16989268  0.11760783  0.18096700
#&gt; 3   0.4711538 -0.09080494 -0.05104846 -0.17166916 -0.21455242 -0.21725391
#&gt; 4   0.4711538  0.36370490  0.54112657  0.50724821  0.55508565  0.57773785
#&gt; 5   0.4711538 -0.04408124  0.07399231 -0.07129909 -0.24018962 -0.23445282
#&gt; 6   0.4711538 -0.03776963  0.17275288  0.01806190 -0.02597539 -0.06284454
#&gt; 7   0.4711538 -0.06930728 -0.19928456 -0.09137261  0.01116043  0.06506517
#&gt; 8   0.4711538  0.27158233  0.24933653  0.11611522  0.12804487  0.04118115
#&gt; 9   0.4711538  0.76949497  0.60296556  0.47237794  0.51581382  0.49885092
#&gt; 10  0.4711538  0.22096539  0.34482052  0.34660816  0.38580378  0.43528451
#&gt; 11  0.4711538  0.87147914  0.84865348  0.76372713  0.73582307  0.76725258
#&gt; 12  0.4711538  0.79792975  0.67828859  0.73747065  0.67844373  0.67908585
#&gt; 13  0.4711538  0.09432664 -0.04344681  0.10780023  0.22488457  0.26144110
#&gt; 14  0.4711538  0.28543133  0.29293086  0.37385135  0.37961001  0.30207755
#&gt; 15  0.4711538  0.30637401  0.27816310  0.18074751  0.01510565  0.05074255
#&gt; 16  0.4711538  0.12893721 -0.07276258 -0.05146556 -0.09988241 -0.06790398
#&gt; 17  0.4711538  0.59910292  0.41302582  0.40055026  0.32477692  0.32429673
#&gt; 18  0.4711538  0.60665328  0.51461671  0.70351041  0.63093215  0.60232625
#&gt; 19  0.4711538  0.18381206  0.36596047  0.33591603  0.25289460  0.21859872
#&gt; 20  0.4711538  0.28422822  0.15202852  0.29980632  0.42075827  0.43463142
#&gt; 21  0.4711538  0.35982960  0.40300075  0.63220247  0.58056075  0.55273462
#&gt; 22  0.4711538  0.31574837  0.28422517  0.37116719  0.27156145  0.25529246
#&gt; 23  0.4711538  0.41682757  0.36900849  0.23791176  0.25730930  0.24221472
#&gt; 24  0.4711538  0.30288056  0.15972272  0.19362318  0.07194768  0.07250435
#&gt; 25  0.4711538  0.29650015  0.48867070  0.61025747  0.59737342  0.67704212
#&gt; 26  0.4711538  0.23008536  0.32001822  0.15862645  0.26312675  0.22513847
#&gt; 27  0.4711538  0.67526360  0.68123526  0.58796740  0.51309143  0.44381568
#&gt; 28  0.4711538  0.15222775  0.13544964  0.15605402  0.15868232  0.10574096
#&gt; 29  0.4711538  0.43138914  0.29576924  0.29706087  0.35294305  0.40257625
#&gt; 30  0.4711538  0.13910581  0.26763382  0.10182481  0.12169881  0.13543560
#&gt; 31  0.4711538  0.40295972  0.43810789  0.28684877  0.41632594  0.45388666
#&gt; 32  0.4711538  0.58422149  0.44366239  0.16615851  0.15367980  0.18291151
#&gt; 33  0.4711538  0.69889100  0.72592310  0.57845537  0.50185886  0.51841164
#&gt; 34  0.4711538  0.35960908  0.24234167  0.09364940  0.08428214  0.10528276
#&gt; 35  0.4711538  0.27914959  0.03731133 -0.08896074 -0.06232370 -0.08231459
#&gt; 36  0.4711538  0.38865989  0.39024480  0.44138316  0.47508801  0.42329842
#&gt; 37  0.4711538  0.62200134  0.42145828  0.38142396  0.29675933  0.28947211
#&gt; 38  0.4711538  0.41311694  0.19970983  0.16702613  0.17059545  0.17073272
#&gt; 39  0.4711538  0.31755422  0.28395547  0.17609314  0.23875966  0.25763504
#&gt; 40  0.4711538  0.62628933  0.51627261  0.52025889  0.47789760  0.47304606
#&gt; 41  0.4711538  0.14894845  0.14069540  0.13906223  0.05976750  0.13670893
#&gt; 42  0.4711538  0.64041121  0.49727655  0.49380105  0.53239359  0.51394469
#&gt; 43  0.4711538  0.38696544  0.54930653  0.62650411  0.65244562  0.56755351
#&gt; 44  0.4711538  0.24204195  0.05825611  0.02230584 -0.01790809 -0.03785626
#&gt; 45  0.4711538  0.10349021  0.14957660  0.16304594  0.15564790  0.17065395
#&gt; 46  0.4711538  0.63322787  0.64625855  0.55541948  0.65203351  0.63670168
#&gt; 47  0.4711538  0.20557889  0.23864853  0.24328712  0.13063078  0.09743813
#&gt; 48  0.4711538  0.32352238  0.34894312  0.21162810  0.20487572  0.16461876
#&gt; 49  0.4711538  0.64888519  0.52290405  0.50926772  0.62061797  0.59597941
#&gt; 50  0.4711538  0.44153005  0.49754241  0.32749149  0.24840605  0.32456388
#&gt; 51  0.4711538  0.32562433  0.23887414  0.26764033  0.24950898  0.30432045
#&gt; 52  0.4711538 -0.23250098 -0.28713647 -0.09216174 -0.12709475 -0.18324647
#&gt; 53  0.4711538  0.53388610  0.47710127  0.60836140  0.48273912  0.43334108
#&gt; 54  0.4711538  0.64191356  0.44931093  0.46371798  0.45275305  0.46653696
#&gt; 55  0.4711538  0.05279255  0.06829351  0.15306458  0.25200214  0.21249173
#&gt; 56  0.4711538  0.59808020  0.64333345  0.53741245  0.64108173  0.57876914
#&gt; 57  0.4711538  0.53093147  0.62138656  0.92046148  0.93004391  0.95130430
#&gt; 58  0.4711538  0.64943097  0.57141374  0.66800038  0.64835800  0.65566321
#&gt; 59  0.4711538  0.42541400  0.43027409  0.30117492  0.36183156  0.29992796
#&gt; 60  0.4711538  0.24537249  0.29963849  0.42931558  0.51048830  0.58927966
#&gt; 61  0.4711538  0.64269314  0.62785202  0.75163561  0.68045267  0.67000184
#&gt; 62  0.4711538  0.51277761  0.60877778  0.75493489  0.66735142  0.63862193
#&gt; 63  0.4711538  0.53377378  0.53228159  0.56245626  0.58414332  0.61176055
#&gt; 64  0.4711538  0.79099666  0.90572246  0.92244949  0.93001276  0.93454809
#&gt; 65  0.4711538  0.73768777  0.61339931  0.72362105  0.70536287  0.69970096
#&gt; 66  0.4711538  0.70767466  0.53408924  0.50675818  0.52181506  0.54559559
#&gt; 67  0.4711538  0.96312042  1.17012215  1.08116795  1.22497425  1.21728258
#&gt; 68  0.4711538  0.31575995  0.57179559  0.77297374  0.78532935  0.78484987
#&gt; 69  0.4711538  0.69505872  0.78176548  0.74300700  0.72711033  0.70750770
#&gt; 70  0.4711538  0.72276362  0.90232185  0.89364576  0.84428623  0.92659977
#&gt; 71  0.4711538  0.50950893  0.39503961  0.45591683  0.38297596  0.35086204
#&gt; 72  0.4711538  0.14720074  0.13538571 -0.04473829 -0.05529233  0.02748516
#&gt; 73  0.4711538  0.49275110  0.44937896  0.41856171  0.62470016  0.61654596
#&gt; 74  0.4711538  0.65674324  0.69439259  0.75479685  0.88511667  0.92560996
#&gt; 75  0.4711538  0.68716407  0.57541914  0.59945962  0.54581071  0.55228791
#&gt; 76  0.4711538  0.54839542  0.50508123  0.52627725  0.55765709  0.52543838
#&gt; 77  0.4711538  0.77317727  0.79812663  0.93073165  1.10301473  1.08723742
#&gt; 78  0.4711538  0.85322027  0.76128342  0.81061207  0.85796753  0.87947603
#&gt; 79  0.4711538  0.81659194  0.90228252  0.80744839  0.70383361  0.68468090
#&gt; 80  0.4711538  0.55964651  0.44326524  0.39507689  0.36149039  0.32071350
#&gt; 81  0.4711538  0.87105473  0.86695796  0.89177640  0.74816339  0.69831750
#&gt; 82  0.4711538  0.47715869  0.68930595  0.71280202  0.73606020  0.78321326
#&gt; 83  0.4711538  0.80974821  0.87138779  0.97466313  0.93082943  0.95560886
#&gt; 84  0.4711538  0.67739807  0.85743609  0.98894432  0.96011041  0.90800271
#&gt; 85  0.4711538  0.57131444  0.34250950  0.33855791  0.31118498  0.31383288
#&gt; 86  0.4711538  0.84958765  0.97611051  0.93090902  0.91560248  0.86222031
#&gt; 87  0.4711538  0.57644613  0.41449248  0.48714466  0.54811918  0.57041511
#&gt; 88  0.4711538  0.75932310  0.71214369  0.52234742  0.59011684  0.59023780
#&gt; 89  0.4711538  0.53031516  0.47090892  0.42433053  0.38847912  0.39218094
#&gt; 90  0.4711538  0.76770402  1.07649866  1.00864429  1.06363018  1.09017457
#&gt; 91  0.4711538  0.38643842  0.37696993  0.44452861  0.49450298  0.46628856
#&gt; 92  0.4711538  0.92591633  1.03707888  0.96084369  0.95688931  0.93400393
#&gt; 93  0.4711538  0.66726042  0.89247800  0.87390628  0.87335977  0.95801535
#&gt; 94  0.4711538  0.32634752  0.41373057  0.48066349  0.67273089  0.62115180
#&gt; 95  0.4711538  0.50472276  0.77159222  0.71730564  0.62350221  0.64335334
#&gt; 96  0.4711538  0.34622269  0.33150717  0.49412629  0.44574013  0.46889514
#&gt; 97  0.4711538  0.55805257  0.50280611  0.58541977  0.52239953  0.53556273
#&gt; 98  0.4711538  0.78090964  0.73429355  0.79385683  0.86651416  0.88151677
#&gt; 99  0.4711538  0.21116352  0.10917861  0.02565398  0.18342015  0.15222876
#&gt; 100 0.4711538  0.66672702  0.78264411  0.86306662  0.75733969  0.77632472
#&gt; 101 0.4711538  0.45317545  0.50149615  0.62617428  0.70904267  0.78134354
#&gt; 102 0.4711538  0.74435376  0.66135006  0.72568147  0.70203564  0.77593538
#&gt; 103 0.4711538  0.34690226  0.56605434  0.52782336  0.50951738  0.46795757
#&gt; 104 0.4711538  0.69496014  0.80515138  0.78871059  0.78008789  0.78042831
#&gt;            [,7]         [,8]         [,9]       [,10]       [,11]
#&gt; 1    0.64037279  0.627340571  0.651243676  0.65354280  0.65838797
#&gt; 2    0.21304385  0.202666528  0.206463548  0.21046038  0.20470356
#&gt; 3   -0.22444089 -0.193652144 -0.201652437 -0.20167289 -0.20081532
#&gt; 4    0.58413761  0.600377920  0.608768219  0.60784745  0.60193905
#&gt; 5   -0.26327049 -0.311781941 -0.310765976 -0.31066830 -0.31401382
#&gt; 6   -0.10341096 -0.076840858 -0.080016598 -0.08436785 -0.08777135
#&gt; 7    0.10261786  0.132750517  0.144750243  0.13944940  0.14173177
#&gt; 8    0.04809780  0.063736599  0.063261540  0.07570783  0.07715150
#&gt; 9    0.44543808  0.444943670  0.447021225  0.44582742  0.44748513
#&gt; 10   0.43490588  0.407005593  0.413663760  0.41349216  0.41350336
#&gt; 11   0.78695284  0.777623618  0.783734315  0.78262765  0.77949531
#&gt; 12   0.65654818  0.642154505  0.633436560  0.63197252  0.62875264
#&gt; 13   0.21708341  0.187509114  0.186533541  0.17822088  0.17842513
#&gt; 14   0.28651410  0.260501290  0.279081223  0.27196942  0.26996735
#&gt; 15   0.05784774  0.095949877  0.090894676  0.08865039  0.09080522
#&gt; 16  -0.06239212 -0.039505632 -0.023469898 -0.02045198 -0.02715190
#&gt; 17   0.33482409  0.336193547  0.335468481  0.33501592  0.33670840
#&gt; 18   0.59257402  0.580678556  0.581449676  0.58013547  0.57927640
#&gt; 19   0.24272344  0.246701307  0.240991178  0.23822863  0.23157123
#&gt; 20   0.40555564  0.386074751  0.400419290  0.40843493  0.40860630
#&gt; 21   0.53582205  0.549336181  0.539598759  0.54139679  0.54098845
#&gt; 22   0.27214775  0.265323031  0.262889367  0.27124503  0.27372049
#&gt; 23   0.26310951  0.254264842  0.244111736  0.24044626  0.24169731
#&gt; 24   0.10789143  0.136298989  0.142908568  0.14863967  0.15404679
#&gt; 25   0.62754156  0.650367844  0.644944061  0.64644697  0.64416177
#&gt; 26   0.18477380  0.190402191  0.199245619  0.20152378  0.20582432
#&gt; 27   0.44358238  0.454283166  0.446210009  0.43311399  0.43568840
#&gt; 28   0.13769251  0.118081488  0.117589648  0.11048814  0.11155803
#&gt; 29   0.42759376  0.424018002  0.417256036  0.42362830  0.42160066
#&gt; 30   0.10952676  0.168692282  0.174041713  0.17387211  0.17480429
#&gt; 31   0.45876287  0.432435790  0.425259491  0.43329412  0.43856907
#&gt; 32   0.11742399  0.116981896  0.108778824  0.10636129  0.10689920
#&gt; 33   0.47697376  0.450738829  0.452062165  0.44881973  0.44992624
#&gt; 34   0.09863470  0.095862956  0.092253997  0.09980718  0.10084230
#&gt; 35  -0.08390506 -0.085155814 -0.086690885 -0.08262604 -0.08272575
#&gt; 36   0.45381739  0.433667887  0.449594388  0.44854107  0.44960414
#&gt; 37   0.30022320  0.311627620  0.315020647  0.31958491  0.32067580
#&gt; 38   0.15959719  0.160997289  0.151222415  0.15079738  0.14817778
#&gt; 39   0.27800144  0.253643110  0.255071837  0.25875102  0.25674198
#&gt; 40   0.51555833  0.530347073  0.528402618  0.52790558  0.52538704
#&gt; 41   0.09275154  0.101869980  0.090604733  0.09445259  0.09150467
#&gt; 42   0.50207194  0.483136866  0.487491071  0.48860245  0.49212211
#&gt; 43   0.57336835  0.573091866  0.546609274  0.54001848  0.54366888
#&gt; 44  -0.01451487 -0.004369241 -0.002647953 -0.00844687 -0.01073887
#&gt; 45   0.19657318  0.164988597  0.170522098  0.16781405  0.16715155
#&gt; 46   0.65287559  0.645084587  0.651535848  0.65177845  0.65178893
#&gt; 47   0.12452036  0.119913760  0.117053912  0.11873700  0.11591426
#&gt; 48   0.18275993  0.166998459  0.160605969  0.16869180  0.16855238
#&gt; 49   0.58006784  0.613009102  0.608873759  0.60785525  0.61021103
#&gt; 50   0.33208894  0.314978063  0.311974842  0.30517646  0.31174053
#&gt; 51   0.32816749  0.318321881  0.320797741  0.31281691  0.31540371
#&gt; 52  -0.19584259 -0.184768370 -0.177691131 -0.18225253 -0.18172040
#&gt; 53   0.40794213  0.415136651  0.416044038  0.42408314  0.42075636
#&gt; 54   0.46480524  0.479688395  0.471302624  0.46613648  0.46656474
#&gt; 55   0.23097197  0.213772954  0.189358085  0.18930563  0.19050731
#&gt; 56   0.57331393  0.574558380  0.579775660  0.57922184  0.57800858
#&gt; 57   0.96183872  0.975414458  0.968855613  0.96385549  0.96028958
#&gt; 58   0.64361788  0.631632631  0.641013340  0.63785489  0.64045306
#&gt; 59   0.28643229  0.289148607  0.278791345  0.28784917  0.28782462
#&gt; 60   0.55978204  0.559023840  0.561630138  0.55671889  0.55726966
#&gt; 61   0.65787202  0.659412106  0.650588243  0.64930310  0.65091617
#&gt; 62   0.60705201  0.603977438  0.589826600  0.58812271  0.58793743
#&gt; 63   0.63813827  0.617717657  0.614454772  0.61166047  0.60985403
#&gt; 64   1.00166279  1.008968255  1.008852814  1.01022555  1.00666729
#&gt; 65   0.69297263  0.697694744  0.689810628  0.69214943  0.69038662
#&gt; 66   0.53663407  0.532369158  0.535934708  0.53171176  0.53102146
#&gt; 67   1.22111150  1.202569147  1.194030443  1.19310867  1.19228184
#&gt; 68   0.80071187  0.812462410  0.796883689  0.80360414  0.80689017
#&gt; 69   0.74791867  0.774669023  0.764357440  0.76435231  0.76730276
#&gt; 70   0.93952180  0.926356875  0.916496158  0.91637035  0.92383169
#&gt; 71   0.31179970  0.319584982  0.342996678  0.34334588  0.34349096
#&gt; 72   0.08069763  0.064883087  0.053282640  0.04500807  0.04571864
#&gt; 73   0.63914960  0.656024336  0.647841400  0.64971036  0.64930911
#&gt; 74   0.94540783  0.945531101  0.947433351  0.95548576  0.95086945
#&gt; 75   0.56609663  0.581051527  0.586510546  0.58350518  0.58195688
#&gt; 76   0.49807985  0.507124137  0.503700114  0.50352891  0.50289031
#&gt; 77   1.06463806  1.090636226  1.099163425  1.09692704  1.09684987
#&gt; 78   0.88947890  0.914074686  0.921993535  0.92611779  0.92473772
#&gt; 79   0.70672170  0.689699520  0.693322761  0.69306283  0.69031633
#&gt; 80   0.30181332  0.296560012  0.282907508  0.28672758  0.28334638
#&gt; 81   0.69871492  0.692603330  0.692711040  0.69448149  0.69353087
#&gt; 82   0.73754433  0.755515607  0.753806256  0.76075515  0.76006115
#&gt; 83   0.95554583  0.981114506  0.967899112  0.96789876  0.97167928
#&gt; 84   0.92460814  0.928255751  0.934569121  0.93157477  0.93560641
#&gt; 85   0.31932547  0.326702214  0.334191767  0.33780085  0.33863677
#&gt; 86   0.82950069  0.806588554  0.823792983  0.82202715  0.81981455
#&gt; 87   0.56750119  0.560439488  0.549720853  0.54609905  0.54656224
#&gt; 88   0.57484476  0.588841816  0.582284530  0.57334028  0.57098492
#&gt; 89   0.44028895  0.455790854  0.462215323  0.46149391  0.46635298
#&gt; 90   1.08703587  1.113909884  1.123382027  1.12669615  1.12559691
#&gt; 91   0.50591629  0.528734399  0.542033081  0.53789411  0.54025902
#&gt; 92   0.95078882  0.944122848  0.933909143  0.93429933  0.92818920
#&gt; 93   0.95048831  0.984993815  0.999870929  0.99916201  0.99970721
#&gt; 94   0.63222931  0.617803323  0.604620965  0.60316670  0.59998131
#&gt; 95   0.60173453  0.598838861  0.615665753  0.61062288  0.61003734
#&gt; 96   0.42461082  0.393735123  0.382307431  0.38698306  0.38928062
#&gt; 97   0.55493331  0.545341350  0.548945997  0.55196226  0.55110104
#&gt; 98   0.84875293  0.849088124  0.833445596  0.82896512  0.82882885
#&gt; 99   0.12817884  0.125184677  0.142524174  0.14250387  0.14467219
#&gt; 100  0.76010896  0.740234308  0.744642249  0.75159300  0.75722807
#&gt; 101  0.80270481  0.778624924  0.777761525  0.78102072  0.77766043
#&gt; 102  0.77647730  0.755860583  0.764875857  0.76840548  0.77181270
#&gt; 103  0.50588630  0.488855008  0.495423757  0.50188675  0.50526664
#&gt; 104  0.81071639  0.804180721  0.825464815  0.81861016  0.81635531</div><div class='input'><span class='co'>#Truncated to [0;1] predicted values (true probabilities)</span>
<span class='no'>modpls.aze</span>$<span class='no'>Probs.trc</span></div><div class='output co'>#&gt;          [,1]       [,2]       [,3]       [,4]       [,5]       [,6]       [,7]
#&gt; 1   0.4711538 0.46105744 0.63458141 0.67961627 0.69452246 0.64534767 0.64037279
#&gt; 2   0.4711538 0.26911816 0.26581497 0.16989268 0.11760783 0.18096700 0.21304385
#&gt; 3   0.4711538 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000
#&gt; 4   0.4711538 0.36370490 0.54112657 0.50724821 0.55508565 0.57773785 0.58413761
#&gt; 5   0.4711538 0.00000000 0.07399231 0.00000000 0.00000000 0.00000000 0.00000000
#&gt; 6   0.4711538 0.00000000 0.17275288 0.01806190 0.00000000 0.00000000 0.00000000
#&gt; 7   0.4711538 0.00000000 0.00000000 0.00000000 0.01116043 0.06506517 0.10261786
#&gt; 8   0.4711538 0.27158233 0.24933653 0.11611522 0.12804487 0.04118115 0.04809780
#&gt; 9   0.4711538 0.76949497 0.60296556 0.47237794 0.51581382 0.49885092 0.44543808
#&gt; 10  0.4711538 0.22096539 0.34482052 0.34660816 0.38580378 0.43528451 0.43490588
#&gt; 11  0.4711538 0.87147914 0.84865348 0.76372713 0.73582307 0.76725258 0.78695284
#&gt; 12  0.4711538 0.79792975 0.67828859 0.73747065 0.67844373 0.67908585 0.65654818
#&gt; 13  0.4711538 0.09432664 0.00000000 0.10780023 0.22488457 0.26144110 0.21708341
#&gt; 14  0.4711538 0.28543133 0.29293086 0.37385135 0.37961001 0.30207755 0.28651410
#&gt; 15  0.4711538 0.30637401 0.27816310 0.18074751 0.01510565 0.05074255 0.05784774
#&gt; 16  0.4711538 0.12893721 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000
#&gt; 17  0.4711538 0.59910292 0.41302582 0.40055026 0.32477692 0.32429673 0.33482409
#&gt; 18  0.4711538 0.60665328 0.51461671 0.70351041 0.63093215 0.60232625 0.59257402
#&gt; 19  0.4711538 0.18381206 0.36596047 0.33591603 0.25289460 0.21859872 0.24272344
#&gt; 20  0.4711538 0.28422822 0.15202852 0.29980632 0.42075827 0.43463142 0.40555564
#&gt; 21  0.4711538 0.35982960 0.40300075 0.63220247 0.58056075 0.55273462 0.53582205
#&gt; 22  0.4711538 0.31574837 0.28422517 0.37116719 0.27156145 0.25529246 0.27214775
#&gt; 23  0.4711538 0.41682757 0.36900849 0.23791176 0.25730930 0.24221472 0.26310951
#&gt; 24  0.4711538 0.30288056 0.15972272 0.19362318 0.07194768 0.07250435 0.10789143
#&gt; 25  0.4711538 0.29650015 0.48867070 0.61025747 0.59737342 0.67704212 0.62754156
#&gt; 26  0.4711538 0.23008536 0.32001822 0.15862645 0.26312675 0.22513847 0.18477380
#&gt; 27  0.4711538 0.67526360 0.68123526 0.58796740 0.51309143 0.44381568 0.44358238
#&gt; 28  0.4711538 0.15222775 0.13544964 0.15605402 0.15868232 0.10574096 0.13769251
#&gt; 29  0.4711538 0.43138914 0.29576924 0.29706087 0.35294305 0.40257625 0.42759376
#&gt; 30  0.4711538 0.13910581 0.26763382 0.10182481 0.12169881 0.13543560 0.10952676
#&gt; 31  0.4711538 0.40295972 0.43810789 0.28684877 0.41632594 0.45388666 0.45876287
#&gt; 32  0.4711538 0.58422149 0.44366239 0.16615851 0.15367980 0.18291151 0.11742399
#&gt; 33  0.4711538 0.69889100 0.72592310 0.57845537 0.50185886 0.51841164 0.47697376
#&gt; 34  0.4711538 0.35960908 0.24234167 0.09364940 0.08428214 0.10528276 0.09863470
#&gt; 35  0.4711538 0.27914959 0.03731133 0.00000000 0.00000000 0.00000000 0.00000000
#&gt; 36  0.4711538 0.38865989 0.39024480 0.44138316 0.47508801 0.42329842 0.45381739
#&gt; 37  0.4711538 0.62200134 0.42145828 0.38142396 0.29675933 0.28947211 0.30022320
#&gt; 38  0.4711538 0.41311694 0.19970983 0.16702613 0.17059545 0.17073272 0.15959719
#&gt; 39  0.4711538 0.31755422 0.28395547 0.17609314 0.23875966 0.25763504 0.27800144
#&gt; 40  0.4711538 0.62628933 0.51627261 0.52025889 0.47789760 0.47304606 0.51555833
#&gt; 41  0.4711538 0.14894845 0.14069540 0.13906223 0.05976750 0.13670893 0.09275154
#&gt; 42  0.4711538 0.64041121 0.49727655 0.49380105 0.53239359 0.51394469 0.50207194
#&gt; 43  0.4711538 0.38696544 0.54930653 0.62650411 0.65244562 0.56755351 0.57336835
#&gt; 44  0.4711538 0.24204195 0.05825611 0.02230584 0.00000000 0.00000000 0.00000000
#&gt; 45  0.4711538 0.10349021 0.14957660 0.16304594 0.15564790 0.17065395 0.19657318
#&gt; 46  0.4711538 0.63322787 0.64625855 0.55541948 0.65203351 0.63670168 0.65287559
#&gt; 47  0.4711538 0.20557889 0.23864853 0.24328712 0.13063078 0.09743813 0.12452036
#&gt; 48  0.4711538 0.32352238 0.34894312 0.21162810 0.20487572 0.16461876 0.18275993
#&gt; 49  0.4711538 0.64888519 0.52290405 0.50926772 0.62061797 0.59597941 0.58006784
#&gt; 50  0.4711538 0.44153005 0.49754241 0.32749149 0.24840605 0.32456388 0.33208894
#&gt; 51  0.4711538 0.32562433 0.23887414 0.26764033 0.24950898 0.30432045 0.32816749
#&gt; 52  0.4711538 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000
#&gt; 53  0.4711538 0.53388610 0.47710127 0.60836140 0.48273912 0.43334108 0.40794213
#&gt; 54  0.4711538 0.64191356 0.44931093 0.46371798 0.45275305 0.46653696 0.46480524
#&gt; 55  0.4711538 0.05279255 0.06829351 0.15306458 0.25200214 0.21249173 0.23097197
#&gt; 56  0.4711538 0.59808020 0.64333345 0.53741245 0.64108173 0.57876914 0.57331393
#&gt; 57  0.4711538 0.53093147 0.62138656 0.92046148 0.93004391 0.95130430 0.96183872
#&gt; 58  0.4711538 0.64943097 0.57141374 0.66800038 0.64835800 0.65566321 0.64361788
#&gt; 59  0.4711538 0.42541400 0.43027409 0.30117492 0.36183156 0.29992796 0.28643229
#&gt; 60  0.4711538 0.24537249 0.29963849 0.42931558 0.51048830 0.58927966 0.55978204
#&gt; 61  0.4711538 0.64269314 0.62785202 0.75163561 0.68045267 0.67000184 0.65787202
#&gt; 62  0.4711538 0.51277761 0.60877778 0.75493489 0.66735142 0.63862193 0.60705201
#&gt; 63  0.4711538 0.53377378 0.53228159 0.56245626 0.58414332 0.61176055 0.63813827
#&gt; 64  0.4711538 0.79099666 0.90572246 0.92244949 0.93001276 0.93454809 1.00000000
#&gt; 65  0.4711538 0.73768777 0.61339931 0.72362105 0.70536287 0.69970096 0.69297263
#&gt; 66  0.4711538 0.70767466 0.53408924 0.50675818 0.52181506 0.54559559 0.53663407
#&gt; 67  0.4711538 0.96312042 1.00000000 1.00000000 1.00000000 1.00000000 1.00000000
#&gt; 68  0.4711538 0.31575995 0.57179559 0.77297374 0.78532935 0.78484987 0.80071187
#&gt; 69  0.4711538 0.69505872 0.78176548 0.74300700 0.72711033 0.70750770 0.74791867
#&gt; 70  0.4711538 0.72276362 0.90232185 0.89364576 0.84428623 0.92659977 0.93952180
#&gt; 71  0.4711538 0.50950893 0.39503961 0.45591683 0.38297596 0.35086204 0.31179970
#&gt; 72  0.4711538 0.14720074 0.13538571 0.00000000 0.00000000 0.02748516 0.08069763
#&gt; 73  0.4711538 0.49275110 0.44937896 0.41856171 0.62470016 0.61654596 0.63914960
#&gt; 74  0.4711538 0.65674324 0.69439259 0.75479685 0.88511667 0.92560996 0.94540783
#&gt; 75  0.4711538 0.68716407 0.57541914 0.59945962 0.54581071 0.55228791 0.56609663
#&gt; 76  0.4711538 0.54839542 0.50508123 0.52627725 0.55765709 0.52543838 0.49807985
#&gt; 77  0.4711538 0.77317727 0.79812663 0.93073165 1.00000000 1.00000000 1.00000000
#&gt; 78  0.4711538 0.85322027 0.76128342 0.81061207 0.85796753 0.87947603 0.88947890
#&gt; 79  0.4711538 0.81659194 0.90228252 0.80744839 0.70383361 0.68468090 0.70672170
#&gt; 80  0.4711538 0.55964651 0.44326524 0.39507689 0.36149039 0.32071350 0.30181332
#&gt; 81  0.4711538 0.87105473 0.86695796 0.89177640 0.74816339 0.69831750 0.69871492
#&gt; 82  0.4711538 0.47715869 0.68930595 0.71280202 0.73606020 0.78321326 0.73754433
#&gt; 83  0.4711538 0.80974821 0.87138779 0.97466313 0.93082943 0.95560886 0.95554583
#&gt; 84  0.4711538 0.67739807 0.85743609 0.98894432 0.96011041 0.90800271 0.92460814
#&gt; 85  0.4711538 0.57131444 0.34250950 0.33855791 0.31118498 0.31383288 0.31932547
#&gt; 86  0.4711538 0.84958765 0.97611051 0.93090902 0.91560248 0.86222031 0.82950069
#&gt; 87  0.4711538 0.57644613 0.41449248 0.48714466 0.54811918 0.57041511 0.56750119
#&gt; 88  0.4711538 0.75932310 0.71214369 0.52234742 0.59011684 0.59023780 0.57484476
#&gt; 89  0.4711538 0.53031516 0.47090892 0.42433053 0.38847912 0.39218094 0.44028895
#&gt; 90  0.4711538 0.76770402 1.00000000 1.00000000 1.00000000 1.00000000 1.00000000
#&gt; 91  0.4711538 0.38643842 0.37696993 0.44452861 0.49450298 0.46628856 0.50591629
#&gt; 92  0.4711538 0.92591633 1.00000000 0.96084369 0.95688931 0.93400393 0.95078882
#&gt; 93  0.4711538 0.66726042 0.89247800 0.87390628 0.87335977 0.95801535 0.95048831
#&gt; 94  0.4711538 0.32634752 0.41373057 0.48066349 0.67273089 0.62115180 0.63222931
#&gt; 95  0.4711538 0.50472276 0.77159222 0.71730564 0.62350221 0.64335334 0.60173453
#&gt; 96  0.4711538 0.34622269 0.33150717 0.49412629 0.44574013 0.46889514 0.42461082
#&gt; 97  0.4711538 0.55805257 0.50280611 0.58541977 0.52239953 0.53556273 0.55493331
#&gt; 98  0.4711538 0.78090964 0.73429355 0.79385683 0.86651416 0.88151677 0.84875293
#&gt; 99  0.4711538 0.21116352 0.10917861 0.02565398 0.18342015 0.15222876 0.12817884
#&gt; 100 0.4711538 0.66672702 0.78264411 0.86306662 0.75733969 0.77632472 0.76010896
#&gt; 101 0.4711538 0.45317545 0.50149615 0.62617428 0.70904267 0.78134354 0.80270481
#&gt; 102 0.4711538 0.74435376 0.66135006 0.72568147 0.70203564 0.77593538 0.77647730
#&gt; 103 0.4711538 0.34690226 0.56605434 0.52782336 0.50951738 0.46795757 0.50588630
#&gt; 104 0.4711538 0.69496014 0.80515138 0.78871059 0.78008789 0.78042831 0.81071639
#&gt;           [,8]       [,9]      [,10]      [,11]
#&gt; 1   0.62734057 0.65124368 0.65354280 0.65838797
#&gt; 2   0.20266653 0.20646355 0.21046038 0.20470356
#&gt; 3   0.00000000 0.00000000 0.00000000 0.00000000
#&gt; 4   0.60037792 0.60876822 0.60784745 0.60193905
#&gt; 5   0.00000000 0.00000000 0.00000000 0.00000000
#&gt; 6   0.00000000 0.00000000 0.00000000 0.00000000
#&gt; 7   0.13275052 0.14475024 0.13944940 0.14173177
#&gt; 8   0.06373660 0.06326154 0.07570783 0.07715150
#&gt; 9   0.44494367 0.44702123 0.44582742 0.44748513
#&gt; 10  0.40700559 0.41366376 0.41349216 0.41350336
#&gt; 11  0.77762362 0.78373432 0.78262765 0.77949531
#&gt; 12  0.64215450 0.63343656 0.63197252 0.62875264
#&gt; 13  0.18750911 0.18653354 0.17822088 0.17842513
#&gt; 14  0.26050129 0.27908122 0.27196942 0.26996735
#&gt; 15  0.09594988 0.09089468 0.08865039 0.09080522
#&gt; 16  0.00000000 0.00000000 0.00000000 0.00000000
#&gt; 17  0.33619355 0.33546848 0.33501592 0.33670840
#&gt; 18  0.58067856 0.58144968 0.58013547 0.57927640
#&gt; 19  0.24670131 0.24099118 0.23822863 0.23157123
#&gt; 20  0.38607475 0.40041929 0.40843493 0.40860630
#&gt; 21  0.54933618 0.53959876 0.54139679 0.54098845
#&gt; 22  0.26532303 0.26288937 0.27124503 0.27372049
#&gt; 23  0.25426484 0.24411174 0.24044626 0.24169731
#&gt; 24  0.13629899 0.14290857 0.14863967 0.15404679
#&gt; 25  0.65036784 0.64494406 0.64644697 0.64416177
#&gt; 26  0.19040219 0.19924562 0.20152378 0.20582432
#&gt; 27  0.45428317 0.44621001 0.43311399 0.43568840
#&gt; 28  0.11808149 0.11758965 0.11048814 0.11155803
#&gt; 29  0.42401800 0.41725604 0.42362830 0.42160066
#&gt; 30  0.16869228 0.17404171 0.17387211 0.17480429
#&gt; 31  0.43243579 0.42525949 0.43329412 0.43856907
#&gt; 32  0.11698190 0.10877882 0.10636129 0.10689920
#&gt; 33  0.45073883 0.45206217 0.44881973 0.44992624
#&gt; 34  0.09586296 0.09225400 0.09980718 0.10084230
#&gt; 35  0.00000000 0.00000000 0.00000000 0.00000000
#&gt; 36  0.43366789 0.44959439 0.44854107 0.44960414
#&gt; 37  0.31162762 0.31502065 0.31958491 0.32067580
#&gt; 38  0.16099729 0.15122241 0.15079738 0.14817778
#&gt; 39  0.25364311 0.25507184 0.25875102 0.25674198
#&gt; 40  0.53034707 0.52840262 0.52790558 0.52538704
#&gt; 41  0.10186998 0.09060473 0.09445259 0.09150467
#&gt; 42  0.48313687 0.48749107 0.48860245 0.49212211
#&gt; 43  0.57309187 0.54660927 0.54001848 0.54366888
#&gt; 44  0.00000000 0.00000000 0.00000000 0.00000000
#&gt; 45  0.16498860 0.17052210 0.16781405 0.16715155
#&gt; 46  0.64508459 0.65153585 0.65177845 0.65178893
#&gt; 47  0.11991376 0.11705391 0.11873700 0.11591426
#&gt; 48  0.16699846 0.16060597 0.16869180 0.16855238
#&gt; 49  0.61300910 0.60887376 0.60785525 0.61021103
#&gt; 50  0.31497806 0.31197484 0.30517646 0.31174053
#&gt; 51  0.31832188 0.32079774 0.31281691 0.31540371
#&gt; 52  0.00000000 0.00000000 0.00000000 0.00000000
#&gt; 53  0.41513665 0.41604404 0.42408314 0.42075636
#&gt; 54  0.47968839 0.47130262 0.46613648 0.46656474
#&gt; 55  0.21377295 0.18935809 0.18930563 0.19050731
#&gt; 56  0.57455838 0.57977566 0.57922184 0.57800858
#&gt; 57  0.97541446 0.96885561 0.96385549 0.96028958
#&gt; 58  0.63163263 0.64101334 0.63785489 0.64045306
#&gt; 59  0.28914861 0.27879135 0.28784917 0.28782462
#&gt; 60  0.55902384 0.56163014 0.55671889 0.55726966
#&gt; 61  0.65941211 0.65058824 0.64930310 0.65091617
#&gt; 62  0.60397744 0.58982660 0.58812271 0.58793743
#&gt; 63  0.61771766 0.61445477 0.61166047 0.60985403
#&gt; 64  1.00000000 1.00000000 1.00000000 1.00000000
#&gt; 65  0.69769474 0.68981063 0.69214943 0.69038662
#&gt; 66  0.53236916 0.53593471 0.53171176 0.53102146
#&gt; 67  1.00000000 1.00000000 1.00000000 1.00000000
#&gt; 68  0.81246241 0.79688369 0.80360414 0.80689017
#&gt; 69  0.77466902 0.76435744 0.76435231 0.76730276
#&gt; 70  0.92635688 0.91649616 0.91637035 0.92383169
#&gt; 71  0.31958498 0.34299668 0.34334588 0.34349096
#&gt; 72  0.06488309 0.05328264 0.04500807 0.04571864
#&gt; 73  0.65602434 0.64784140 0.64971036 0.64930911
#&gt; 74  0.94553110 0.94743335 0.95548576 0.95086945
#&gt; 75  0.58105153 0.58651055 0.58350518 0.58195688
#&gt; 76  0.50712414 0.50370011 0.50352891 0.50289031
#&gt; 77  1.00000000 1.00000000 1.00000000 1.00000000
#&gt; 78  0.91407469 0.92199353 0.92611779 0.92473772
#&gt; 79  0.68969952 0.69332276 0.69306283 0.69031633
#&gt; 80  0.29656001 0.28290751 0.28672758 0.28334638
#&gt; 81  0.69260333 0.69271104 0.69448149 0.69353087
#&gt; 82  0.75551561 0.75380626 0.76075515 0.76006115
#&gt; 83  0.98111451 0.96789911 0.96789876 0.97167928
#&gt; 84  0.92825575 0.93456912 0.93157477 0.93560641
#&gt; 85  0.32670221 0.33419177 0.33780085 0.33863677
#&gt; 86  0.80658855 0.82379298 0.82202715 0.81981455
#&gt; 87  0.56043949 0.54972085 0.54609905 0.54656224
#&gt; 88  0.58884182 0.58228453 0.57334028 0.57098492
#&gt; 89  0.45579085 0.46221532 0.46149391 0.46635298
#&gt; 90  1.00000000 1.00000000 1.00000000 1.00000000
#&gt; 91  0.52873440 0.54203308 0.53789411 0.54025902
#&gt; 92  0.94412285 0.93390914 0.93429933 0.92818920
#&gt; 93  0.98499381 0.99987093 0.99916201 0.99970721
#&gt; 94  0.61780332 0.60462097 0.60316670 0.59998131
#&gt; 95  0.59883886 0.61566575 0.61062288 0.61003734
#&gt; 96  0.39373512 0.38230743 0.38698306 0.38928062
#&gt; 97  0.54534135 0.54894600 0.55196226 0.55110104
#&gt; 98  0.84908812 0.83344560 0.82896512 0.82882885
#&gt; 99  0.12518468 0.14252417 0.14250387 0.14467219
#&gt; 100 0.74023431 0.74464225 0.75159300 0.75722807
#&gt; 101 0.77862492 0.77776152 0.78102072 0.77766043
#&gt; 102 0.75586058 0.76487586 0.76840548 0.77181270
#&gt; 103 0.48885501 0.49542376 0.50188675 0.50526664
#&gt; 104 0.80418072 0.82546481 0.81861016 0.81635531</div><div class='input'><span class='no'>modpls.aze</span>$<span class='no'>Probs</span>-<span class='no'>modpls.aze</span>$<span class='no'>Probs.trc</span></div><div class='output co'>#&gt;     [,1]        [,2]        [,3]         [,4]        [,5]        [,6]
#&gt; 1      0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 2      0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 3      0 -0.09080494 -0.05104846 -0.171669164 -0.21455242 -0.21725391
#&gt; 4      0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 5      0 -0.04408124  0.00000000 -0.071299085 -0.24018962 -0.23445282
#&gt; 6      0 -0.03776963  0.00000000  0.000000000 -0.02597539 -0.06284454
#&gt; 7      0 -0.06930728 -0.19928456 -0.091372612  0.00000000  0.00000000
#&gt; 8      0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 9      0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 10     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 11     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 12     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 13     0  0.00000000 -0.04344681  0.000000000  0.00000000  0.00000000
#&gt; 14     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 15     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 16     0  0.00000000 -0.07276258 -0.051465557 -0.09988241 -0.06790398
#&gt; 17     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 18     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 19     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 20     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 21     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 22     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 23     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 24     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 25     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 26     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 27     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 28     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 29     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 30     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 31     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 32     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 33     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 34     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 35     0  0.00000000  0.00000000 -0.088960742 -0.06232370 -0.08231459
#&gt; 36     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 37     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 38     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 39     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 40     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 41     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 42     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 43     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 44     0  0.00000000  0.00000000  0.000000000 -0.01790809 -0.03785626
#&gt; 45     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 46     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 47     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 48     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 49     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 50     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 51     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 52     0 -0.23250098 -0.28713647 -0.092161735 -0.12709475 -0.18324647
#&gt; 53     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 54     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 55     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 56     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 57     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 58     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 59     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 60     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 61     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 62     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 63     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 64     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 65     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 66     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 67     0  0.00000000  0.17012215  0.081167947  0.22497425  0.21728258
#&gt; 68     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 69     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 70     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 71     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 72     0  0.00000000  0.00000000 -0.044738287 -0.05529233  0.00000000
#&gt; 73     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 74     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 75     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 76     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 77     0  0.00000000  0.00000000  0.000000000  0.10301473  0.08723742
#&gt; 78     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 79     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 80     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 81     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 82     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 83     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 84     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 85     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 86     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 87     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 88     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 89     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 90     0  0.00000000  0.07649866  0.008644293  0.06363018  0.09017457
#&gt; 91     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 92     0  0.00000000  0.03707888  0.000000000  0.00000000  0.00000000
#&gt; 93     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 94     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 95     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 96     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 97     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 98     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 99     0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 100    0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 101    0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 102    0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 103    0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt; 104    0  0.00000000  0.00000000  0.000000000  0.00000000  0.00000000
#&gt;             [,7]         [,8]         [,9]       [,10]        [,11]
#&gt; 1    0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 2    0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 3   -0.224440890 -0.193652144 -0.201652437 -0.20167289 -0.200815325
#&gt; 4    0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 5   -0.263270486 -0.311781941 -0.310765976 -0.31066830 -0.314013823
#&gt; 6   -0.103410961 -0.076840858 -0.080016598 -0.08436785 -0.087771351
#&gt; 7    0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 8    0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 9    0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 10   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 11   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 12   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 13   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 14   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 15   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 16  -0.062392124 -0.039505632 -0.023469898 -0.02045198 -0.027151896
#&gt; 17   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 18   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 19   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 20   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 21   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 22   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 23   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 24   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 25   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 26   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 27   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 28   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 29   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 30   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 31   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 32   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 33   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 34   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 35  -0.083905063 -0.085155814 -0.086690885 -0.08262604 -0.082725745
#&gt; 36   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 37   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 38   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 39   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 40   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 41   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 42   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 43   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 44  -0.014514870 -0.004369241 -0.002647953 -0.00844687 -0.010738872
#&gt; 45   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 46   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 47   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 48   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 49   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 50   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 51   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 52  -0.195842587 -0.184768370 -0.177691131 -0.18225253 -0.181720401
#&gt; 53   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 54   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 55   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 56   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 57   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 58   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 59   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 60   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 61   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 62   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 63   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 64   0.001662791  0.008968255  0.008852814  0.01022555  0.006667285
#&gt; 65   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 66   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 67   0.221111495  0.202569147  0.194030443  0.19310867  0.192281835
#&gt; 68   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 69   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 70   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 71   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 72   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 73   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 74   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 75   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 76   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 77   0.064638063  0.090636226  0.099163425  0.09692704  0.096849873
#&gt; 78   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 79   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 80   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 81   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 82   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 83   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 84   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 85   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 86   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 87   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 88   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 89   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 90   0.087035865  0.113909884  0.123382027  0.12669615  0.125596908
#&gt; 91   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 92   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 93   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 94   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 95   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 96   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 97   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 98   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 99   0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 100  0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 101  0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 102  0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 103  0.000000000  0.000000000  0.000000000  0.00000000  0.000000000
#&gt; 104  0.000000000  0.000000000  0.000000000  0.00000000  0.000000000</div><div class='input'>
<span class='co'>#Repeated cross validation of the model (NK=100 times)</span>
<span class='no'>cv.modpls.aze</span><span class='kw'>&lt;-</span><span class='fu'><a href='cv.plsR.html'>cv.plsR</a></span>(<span class='no'>y</span>~<span class='no'>.</span>,<span class='kw'>data</span><span class='kw'>=</span><span class='no'>aze_compl</span>,<span class='fl'>10</span>,<span class='kw'>NK</span><span class='kw'>=</span><span class='fl'>100</span>, <span class='kw'>verbose</span><span class='kw'>=</span><span class='fl'>FALSE</span>)
<span class='no'>res.cv.modpls.aze</span><span class='kw'>&lt;-</span><span class='fu'><a href='cvtable.html'>cvtable</a></span>(<span class='fu'><a href='https://www.rdocumentation.org/packages/base/topics/summary'>summary</a></span>(<span class='no'>cv.modpls.aze</span>,<span class='kw'>MClassed</span><span class='kw'>=</span><span class='fl'>TRUE</span>))</div><div class='output co'>#&gt; ____************************************************____
#&gt; ____Component____ 1 ____
#&gt; ____Component____ 2 ____
#&gt; ____Component____ 3 ____
#&gt; ____Component____ 4 ____
#&gt; ____Component____ 5 ____
#&gt; ____Component____ 6 ____
#&gt; ____Component____ 7 ____
#&gt; ____Component____ 8 ____
#&gt; ____Component____ 9 ____
#&gt; ____Component____ 10 ____
#&gt; ____Predicting X without NA neither in X nor in Y____
#&gt; ****________________________________________________****
#&gt; 
#&gt; 
#&gt; NK: 1,  2,  3,  4,  5,  6,  7,  8,  9,  10
#&gt; NK: 11,  12,  13,  14,  15,  16,  17,  18,  19,  20
#&gt; NK: 21,  22,  23,  24,  25,  26,  27,  28,  29,  30
#&gt; NK: 31,  32,  33,  34,  35,  36,  37,  38,  39,  40
#&gt; NK: 41,  42,  43,  44,  45,  46,  47,  48,  49,  50
#&gt; NK: 51,  52,  53,  54,  55,  56,  57,  58,  59,  60
#&gt; NK: 61,  62,  63,  64,  65,  66,  67,  68,  69,  70
#&gt; NK: 71,  72,  73,  74,  75,  76,  77,  78,  79,  80
#&gt; NK: 81,  82,  83,  84,  85,  86,  87,  88,  89,  90
#&gt; NK: 91,  92,  93,  94,  95,  96,  97,  98,  99,  100
#&gt; 
#&gt; CV MissClassed criterion:
#&gt;  1  2  3  4  5  6  7  8  9 10 
#&gt; 23 17 23  7  3  4  5  8  7  3 
#&gt; 
#&gt; CV Q2 criterion:
#&gt;   0 
#&gt; 100 
#&gt; 
#&gt; CV Press criterion:
#&gt;  1  2 
#&gt; 72 28 </div><div class='input'><span class='co'>#High discrepancy in the number of component choice using repeated cross validation</span>
<span class='co'>#and missclassed criterion</span>
<span class='fu'><a href='https://www.rdocumentation.org/packages/graphics/topics/plot'>plot</a></span>(<span class='no'>res.cv.modpls.aze</span>)</div><div class='img'><img src='plsR-2.png' alt='' width='700' height='433' /></div><div class='input'>
<span class='fu'><a href='https://www.rdocumentation.org/packages/base/topics/rm'>rm</a></span>(<span class='kw'>list</span><span class='kw'>=</span><span class='fu'><a href='https://www.rdocumentation.org/packages/base/topics/c'>c</a></span>(<span class='st'>"Xaze_compl"</span>,<span class='st'>"yaze_compl"</span>,<span class='st'>"modpls.aze"</span>,<span class='st'>"cv.modpls.aze"</span>,<span class='st'>"res.cv.modpls.aze"</span>))

<span class='co'>#24 predictors</span>
<span class='no'>dimX</span> <span class='kw'>&lt;-</span> <span class='fl'>24</span>
<span class='co'>#2 components</span>
<span class='no'>Astar</span> <span class='kw'>&lt;-</span> <span class='fl'>2</span>
<span class='fu'><a href='simul_data_UniYX.html'>simul_data_UniYX</a></span>(<span class='no'>dimX</span>,<span class='no'>Astar</span>)</div><div class='output co'>#&gt;         Y        X1        X2        X3        X4        X5        X6        X7 
#&gt; -2.665073  3.747882  3.741115 -2.115917  3.723508  3.725596 -2.126918  3.741964 
#&gt;        X8        X9       X10       X11       X12       X13       X14       X15 
#&gt;  3.754633 -2.137155  3.747715  3.737510 -2.130237  3.746253  3.749130 -2.111449 
#&gt;       X16       X17       X18       X19       X20       X21       X22       X23 
#&gt;  3.759967  3.738491 -2.139593  3.746738  3.727426 -2.104919  3.741160  3.747769 
#&gt;       X24 
#&gt; -2.123828 </div><div class='input'><span class='no'>dataAstar2</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://www.rdocumentation.org/packages/base/topics/data.frame'>data.frame</a></span>(<span class='fu'><a href='https://www.rdocumentation.org/packages/base/topics/t'>t</a></span>(<span class='fu'><a href='https://www.rdocumentation.org/packages/base/topics/lapply'>replicate</a></span>(<span class='fl'>250</span>,<span class='fu'><a href='simul_data_UniYX.html'>simul_data_UniYX</a></span>(<span class='no'>dimX</span>,<span class='no'>Astar</span>))))
<span class='no'>modpls.A2</span><span class='kw'>&lt;-</span> <span class='fu'>plsR</span>(<span class='no'>Y</span>~<span class='no'>.</span>,<span class='kw'>data</span><span class='kw'>=</span><span class='no'>dataAstar2</span>,<span class='fl'>10</span>,<span class='kw'>typeVC</span><span class='kw'>=</span><span class='st'>"standard"</span>)</div><div class='output co'>#&gt; ____************************************************____
#&gt; ____TypeVC____ standard ____
#&gt; ____Component____ 1 ____
#&gt; ____Component____ 2 ____
#&gt; ____Component____ 3 ____
#&gt; ____Component____ 4 ____
#&gt; ____Component____ 5 ____
#&gt; ____Component____ 6 ____
#&gt; ____Component____ 7 ____
#&gt; ____Component____ 8 ____
#&gt; ____Component____ 9 ____
#&gt; ____Component____ 10 ____
#&gt; ____Predicting X without NA neither in X nor in Y____
#&gt; ****________________________________________________****
#&gt; </div><div class='input'><span class='no'>modpls.A2</span></div><div class='output co'>#&gt; Number of required components:
#&gt; [1] 10
#&gt; Number of successfully computed components:
#&gt; [1] 10
#&gt; Coefficients:
#&gt;                   [,1]
#&gt; Intercept -0.009376336
#&gt; X1         0.942865629
#&gt; X2         0.130398990
#&gt; X3        -2.216699746
#&gt; X4         0.366847337
#&gt; X5        -1.382907277
#&gt; X6         0.654903912
#&gt; X7        -0.721599870
#&gt; X8        -0.198181944
#&gt; X9         1.251097429
#&gt; X10       -0.618295207
#&gt; X11        1.779644236
#&gt; X12       -0.454442233
#&gt; X13       -1.204981990
#&gt; X14       -0.436332869
#&gt; X15        0.264117846
#&gt; X16        0.014174332
#&gt; X17       -1.088608626
#&gt; X18        0.187329349
#&gt; X19       -0.361584831
#&gt; X20        2.125887411
#&gt; X21        2.721248217
#&gt; X22        1.435109025
#&gt; X23       -0.229628372
#&gt; X24       -0.123457788
#&gt; Leave one out cross validated PRESS, Information criteria and Fit statistics:
#&gt;                  AIC   Q2cum_Y LimQ2_Y        Q2_Y     PRESS_Y        RSS_Y
#&gt; Nb_Comp_0  1747.6689        NA      NA          NA          NA 15650.519945
#&gt; Nb_Comp_1  1308.8763 0.8236784  0.0975  0.82367844 2759.524169  2684.068353
#&gt; Nb_Comp_2  -176.2741 0.9995367  0.0975  0.99737246    7.052507     7.004041
#&gt; Nb_Comp_3  -201.3225 0.9995149  0.0975 -0.04715082    7.334287     6.285803
#&gt; Nb_Comp_4  -201.8328 0.9994290  0.0975 -0.17707799    7.398881     6.223004
#&gt; Nb_Comp_5  -200.0709 0.9993406  0.0975 -0.15479032    7.186264     6.217079
#&gt; Nb_Comp_6  -198.1231 0.9992382  0.0975 -0.15529089    7.182535     6.215783
#&gt; Nb_Comp_7  -196.1281 0.9991314  0.0975 -0.14008626    7.086528     6.215657
#&gt; Nb_Comp_8  -194.1286 0.9990136  0.0975 -0.13564421    7.058775     6.215645
#&gt; Nb_Comp_9  -192.1287 0.9988854  0.0975 -0.12998545    7.023589     6.215643
#&gt; Nb_Comp_10 -190.1287 0.9987501  0.0975 -0.12143466    6.970438     6.215643
#&gt;                 R2_Y R2_residY   RSS_residY PRESS_residY   Q2_residY  LimQ2
#&gt; Nb_Comp_0         NA        NA 249.00000000           NA          NA     NA
#&gt; Nb_Comp_1  0.8284997 0.8284997  42.70356654   43.9040697  0.82367844 0.0975
#&gt; Nb_Comp_2  0.9995525 0.9995525   0.11143440    0.1122055  0.99737246 0.0975
#&gt; Nb_Comp_3  0.9995984 0.9995984   0.10000722    0.1166886 -0.04715082 0.0975
#&gt; Nb_Comp_4  0.9996024 0.9996024   0.09900808    0.1177163 -0.17707799 0.0975
#&gt; Nb_Comp_5  0.9996028 0.9996028   0.09891383    0.1143336 -0.15479032 0.0975
#&gt; Nb_Comp_6  0.9996028 0.9996028   0.09889319    0.1142742 -0.15529089 0.0975
#&gt; Nb_Comp_7  0.9996028 0.9996028   0.09889120    0.1127468 -0.14008626 0.0975
#&gt; Nb_Comp_8  0.9996028 0.9996028   0.09889100    0.1123052 -0.13564421 0.0975
#&gt; Nb_Comp_9  0.9996028 0.9996028   0.09889097    0.1117454 -0.12998545 0.0975
#&gt; Nb_Comp_10 0.9996028 0.9996028   0.09889097    0.1108998 -0.12143466 0.0975
#&gt;            Q2cum_residY    AIC.std   DoF.dof sigmahat.dof     AIC.dof
#&gt; Nb_Comp_0            NA   712.4673  1.000000    7.9280195 63.10490773
#&gt; Nb_Comp_1     0.8236784   273.6746  2.576507    3.2870057 10.95897448
#&gt; Nb_Comp_2     0.9995367 -1211.4758  3.000065    0.1680539  0.02869399
#&gt; Nb_Comp_3     0.9995149 -1236.5242 23.015490    0.1660457  0.03021973
#&gt; Nb_Comp_4     0.9994290 -1237.0344 23.079249    0.1652373  0.02993314
#&gt; Nb_Comp_5     0.9993406 -1235.2725 22.902626    0.1650947  0.02986224
#&gt; Nb_Comp_6     0.9992382 -1233.3247 22.974506    0.1651035  0.02987326
#&gt; Nb_Comp_7     0.9991314 -1231.3297 22.705529    0.1650045  0.02980816
#&gt; Nb_Comp_8     0.9990136 -1229.3302 22.752831    0.1650215  0.02981944
#&gt; Nb_Comp_9     0.9988854 -1227.3303 22.821076    0.1650461  0.02983578
#&gt; Nb_Comp_10    0.9987501 -1225.3303 22.684659    0.1649968  0.02980310
#&gt;                BIC.dof  GMDL.dof DoF.naive sigmahat.naive   AIC.naive
#&gt; Nb_Comp_0  63.99025222  519.8325         1      7.9280195 63.10490773
#&gt; Nb_Comp_1  11.35109102  308.1718         2      3.2898110 10.90943911
#&gt; Nb_Comp_2   0.02988746 -424.9153         3      0.1683937  0.02869672
#&gt; Nb_Comp_3   0.03915810 -329.7222         4      0.1598501  0.02596088
#&gt; Nb_Comp_4   0.03880921 -330.5391         5      0.1593738  0.02590802
#&gt; Nb_Comp_5   0.03865518 -331.5411         6      0.1596240  0.02609135
#&gt; Nb_Comp_6   0.03869474 -331.2009         7      0.1599355  0.02629557
#&gt; Nb_Comp_7   0.03851592 -332.5654         8      0.1602640  0.02650644
#&gt; Nb_Comp_8   0.03854712 -332.3260         9      0.1605959  0.02671954
#&gt; Nb_Comp_9   0.03859226 -331.9803        10      0.1609301  0.02693445
#&gt; Nb_Comp_10  0.03850203 -332.6715        11      0.1612665  0.02715118
#&gt;              BIC.naive GMDL.naive
#&gt; Nb_Comp_0  63.99025222   519.8325
#&gt; Nb_Comp_1  11.21433723   306.8653
#&gt; Nb_Comp_2   0.02989499  -424.4167
#&gt; Nb_Comp_3   0.02740057  -431.7390
#&gt; Nb_Comp_4   0.02769692  -427.0579
#&gt; Nb_Comp_5   0.02824478  -421.3607
#&gt; Nb_Comp_6   0.02881772  -415.6579
#&gt; Nb_Comp_7   0.02940075  -410.0058
#&gt; Nb_Comp_8   0.02998914  -404.4163
#&gt; Nb_Comp_9   0.03058248  -398.8843
#&gt; Nb_Comp_10  0.03118079  -393.4044</div><div class='input'><span class='no'>cv.modpls.A2</span><span class='kw'>&lt;-</span><span class='fu'><a href='cv.plsR.html'>cv.plsR</a></span>(<span class='no'>Y</span>~<span class='no'>.</span>,<span class='kw'>data</span><span class='kw'>=</span><span class='no'>dataAstar2</span>,<span class='fl'>10</span>,<span class='kw'>NK</span><span class='kw'>=</span><span class='fl'>100</span>, <span class='kw'>verbose</span><span class='kw'>=</span><span class='fl'>FALSE</span>)
<span class='no'>res.cv.modpls.A2</span><span class='kw'>&lt;-</span><span class='fu'><a href='cvtable.html'>cvtable</a></span>(<span class='fu'><a href='https://www.rdocumentation.org/packages/base/topics/summary'>summary</a></span>(<span class='no'>cv.modpls.A2</span>,<span class='kw'>verbose</span><span class='kw'>=</span><span class='fl'>FALSE</span>))</div><div class='output co'>#&gt; <span class='error'>Error in is.data.frame(data): object 'dataAstar2' not found</span></div><div class='input'><span class='co'>#Perfect choice for the Q2 criterion in PLSR</span>
<span class='fu'><a href='https://www.rdocumentation.org/packages/graphics/topics/plot'>plot</a></span>(<span class='no'>res.cv.modpls.A2</span>)</div><div class='output co'>#&gt; <span class='error'>Error in plot(res.cv.modpls.A2): object 'res.cv.modpls.A2' not found</span></div><div class='input'>
<span class='co'>#Binarized data.frame</span>
<span class='no'>simbin1</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='https://www.rdocumentation.org/packages/base/topics/data.frame'>data.frame</a></span>(<span class='fu'><a href='dicho.html'>dicho</a></span>(<span class='no'>dataAstar2</span>))
<span class='no'>modpls.B2</span> <span class='kw'>&lt;-</span> <span class='fu'>plsR</span>(<span class='no'>Y</span>~<span class='no'>.</span>,<span class='kw'>data</span><span class='kw'>=</span><span class='no'>simbin1</span>,<span class='fl'>10</span>,<span class='kw'>typeVC</span><span class='kw'>=</span><span class='st'>"standard"</span>,<span class='kw'>MClassed</span><span class='kw'>=</span><span class='fl'>TRUE</span>, <span class='kw'>verbose</span><span class='kw'>=</span><span class='fl'>FALSE</span>)
<span class='no'>modpls.B2</span></div><div class='output co'>#&gt; Number of required components:
#&gt; [1] 10
#&gt; Number of successfully computed components:
#&gt; [1] 4
#&gt; Coefficients:
#&gt;                   [,1]
#&gt; Intercept -0.009409474
#&gt; X1         0.006945571
#&gt; X2         0.006945571
#&gt; X3        -0.296290288
#&gt; X4         0.006945571
#&gt; X5         0.006945571
#&gt; X6        -0.296290288
#&gt; X7         0.006945571
#&gt; X8         0.006945571
#&gt; X9         0.449140169
#&gt; X10        0.006945571
#&gt; X11        0.006945571
#&gt; X12        0.293153796
#&gt; X13        0.006945571
#&gt; X14        0.006945571
#&gt; X15        0.293153796
#&gt; X16        0.006945571
#&gt; X17        0.006945571
#&gt; X18        0.449140169
#&gt; X19        0.006945571
#&gt; X20        0.006945571
#&gt; X21       -0.296290288
#&gt; X22        0.006945571
#&gt; X23        0.006945571
#&gt; X24        0.293153796
#&gt; Leave one out cross validated PRESS, Information criteria and Fit statistics:
#&gt;                 AIC   Q2cum_Y LimQ2_Y          Q2_Y   PRESS_Y     RSS_Y
#&gt; Nb_Comp_0 366.11044        NA      NA            NA        NA 62.304000
#&gt; Nb_Comp_1  54.47132 0.7080322  0.0975  7.080322e-01 18.190760 17.769245
#&gt; Nb_Comp_2 -74.76132 0.8239349  0.0975  3.969708e-01 10.715373 10.512222
#&gt; Nb_Comp_3 -91.09971 0.8108124  0.0975 -7.453191e-02 11.295718  9.768716
#&gt; Nb_Comp_4 -89.11368 0.8108105  0.0975 -1.036324e-05  9.768817  9.768170
#&gt;                R2_Y MissClassed R2_residY RSS_residY PRESS_residY     Q2_residY
#&gt; Nb_Comp_0        NA         118        NA  249.00000           NA            NA
#&gt; Nb_Comp_1 0.7147977          11 0.7147977   71.01538     72.69998  7.080322e-01
#&gt; Nb_Comp_2 0.8312753          13 0.8312753   42.01244     42.82434  3.969708e-01
#&gt; Nb_Comp_3 0.8432089          11 0.8432089   39.04100     45.14371 -7.453191e-02
#&gt; Nb_Comp_4 0.8432176          11 0.8432176   39.03882     39.04140 -1.036324e-05
#&gt;            LimQ2 Q2cum_residY  AIC.std  DoF.dof sigmahat.dof    AIC.dof
#&gt; Nb_Comp_0     NA           NA 712.4673 1.000000    0.5002168 0.25121773
#&gt; Nb_Comp_1 0.0975    0.7080322 400.8281 2.854478    0.2675970 0.07271221
#&gt; Nb_Comp_2 0.0975    0.8239349 271.5955 3.010461    0.2058878 0.04306979
#&gt; Nb_Comp_3 0.0975    0.8108124 255.2571 6.677195    0.1999571 0.04121065
#&gt; Nb_Comp_4 0.0975    0.8108105 257.2431 5.000000    0.1992687 0.04066100
#&gt;              BIC.dof  GMDL.dof DoF.naive sigmahat.naive  AIC.naive  BIC.naive
#&gt; Nb_Comp_0 0.25474225 -167.7150         1      0.5002168 0.25121773 0.25474225
#&gt; Nb_Comp_1 0.07559141 -317.9656         2      0.2676755 0.07222338 0.07424189
#&gt; Nb_Comp_2 0.04486732 -382.2058         3      0.2062998 0.04307032 0.04486878
#&gt; Nb_Comp_3 0.04497119 -379.6046         4      0.1992742 0.04034559 0.04258300
#&gt; Nb_Comp_4 0.04345760 -384.7620         5      0.1996749 0.04066748 0.04347550
#&gt;           GMDL.naive
#&gt; Nb_Comp_0  -167.7150
#&gt; Nb_Comp_1  -320.1839
#&gt; Nb_Comp_2  -381.7421
#&gt; Nb_Comp_3  -387.4593
#&gt; Nb_Comp_4  -384.2630</div><div class='input'><span class='no'>modpls.B2</span>$<span class='no'>Probs</span></div><div class='output co'>#&gt;      [,1]        [,2]        [,3]         [,4]          [,5]
#&gt; 1   0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 2   0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 3   0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 4   0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 5   0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 6   0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 7   0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 8   0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 9   0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 10  0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 11  0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 12  0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 13  0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 14  0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 15  0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 16  0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 17  0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 18  0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 19  0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 20  0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 21  0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 22  0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 23  0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 24  0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 25  0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 26  0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 27  0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 28  0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 29  0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 30  0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 31  0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 32  0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 33  0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 34  0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 35  0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 36  0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 37  0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 38  0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 39  0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 40  0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 41  0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 42  0.472  0.34675721  0.53862249 -0.017703354 -1.887379e-15
#&gt; 43  0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 44  0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 45  0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 46  0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 47  0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 48  0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 49  0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 50  0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 51  0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 52  0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 53  0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 54  0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 55  0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 56  0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 57  0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 58  0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 59  0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 60  0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 61  0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 62  0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 63  0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 64  0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 65  0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 66  0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 67  0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 68  0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 69  0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 70  0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 71  0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 72  0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 73  0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 74  0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 75  0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 76  0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 77  0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 78  0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 79  0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 80  0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 81  0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 82  0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 83  0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 84  0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 85  0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 86  0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 87  0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 88  0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 89  0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 90  0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 91  0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 92  0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 93  0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 94  0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 95  0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 96  0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 97  0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 98  0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 99  0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 100 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 101 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 102 0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 103 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 104 0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 105 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 106 0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 107 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 108 0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 109 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 110 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 111 0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 112 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 113 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 114 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 115 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 116 0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 117 0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 118 0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 119 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 120 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 121 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 122 0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 123 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 124 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 125 0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 126 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 127 0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 128 0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 129 0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 130 0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 131 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 132 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 133 0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 134 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 135 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 136 0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 137 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 138 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 139 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 140 0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 141 0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 142 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 143 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 144 0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 145 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 146 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 147 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 148 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 149 0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 150 0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 151 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 152 0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 153 0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 154 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 155 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 156 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 157 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 158 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 159 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 160 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 161 0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 162 0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 163 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 164 0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 165 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 166 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 167 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 168 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 169 0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 170 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 171 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 172 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 173 0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 174 0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 175 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 176 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 177 0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 178 0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 179 0.472  0.52663889  0.33213206  0.984903754  1.000000e+00
#&gt; 180 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 181 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 182 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 183 0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 184 0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 185 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 186 0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 187 0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 188 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 189 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 190 0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 191 0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 192 0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 193 0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 194 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 195 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 196 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 197 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 198 0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 199 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 200 0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 201 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 202 0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 203 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 204 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 205 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 206 0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 207 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 208 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 209 0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 210 0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 211 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 212 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 213 0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 214 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 215 0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 216 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 217 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 218 0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 219 0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 220 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 221 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 222 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 223 0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 224 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 225 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 226 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 227 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 228 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 229 0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 230 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 231 0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 232 0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 233 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 234 0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 235 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 236 0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 237 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 238 0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 239 0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 240 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 241 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 242 0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 243 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 244 0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 245 0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 246 0.472 -0.06229068 -0.01178995 -0.009257117 -9.409474e-03
#&gt; 247 0.472  0.36216421  0.11016783  0.101839214  1.017197e-01
#&gt; 248 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01
#&gt; 249 0.472  0.59360387  0.87124939  0.879607642  8.794614e-01
#&gt; 250 0.472  1.01805876  0.99320716  0.990703974  9.905905e-01</div><div class='input'><span class='no'>modpls.B2</span>$<span class='no'>Probs.trc</span></div><div class='output co'>#&gt;      [,1]      [,2]      [,3]      [,4]      [,5]
#&gt; 1   0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 2   0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 3   0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 4   0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 5   0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 6   0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 7   0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 8   0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 9   0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 10  0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 11  0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 12  0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 13  0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 14  0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 15  0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 16  0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 17  0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 18  0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 19  0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 20  0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 21  0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 22  0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 23  0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 24  0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 25  0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 26  0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 27  0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 28  0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 29  0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 30  0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 31  0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 32  0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 33  0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 34  0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 35  0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 36  0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 37  0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 38  0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 39  0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 40  0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 41  0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 42  0.472 0.3467572 0.5386225 0.0000000 0.0000000
#&gt; 43  0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 44  0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 45  0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 46  0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 47  0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 48  0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 49  0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 50  0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 51  0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 52  0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 53  0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 54  0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 55  0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 56  0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 57  0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 58  0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 59  0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 60  0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 61  0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 62  0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 63  0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 64  0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 65  0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 66  0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 67  0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 68  0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 69  0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 70  0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 71  0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 72  0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 73  0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 74  0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 75  0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 76  0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 77  0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 78  0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 79  0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 80  0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 81  0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 82  0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 83  0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 84  0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 85  0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 86  0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 87  0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 88  0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 89  0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 90  0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 91  0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 92  0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 93  0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 94  0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 95  0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 96  0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 97  0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 98  0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 99  0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 100 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 101 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 102 0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 103 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 104 0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 105 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 106 0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 107 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 108 0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 109 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 110 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 111 0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 112 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 113 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 114 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 115 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 116 0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 117 0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 118 0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 119 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 120 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 121 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 122 0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 123 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 124 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 125 0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 126 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 127 0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 128 0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 129 0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 130 0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 131 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 132 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 133 0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 134 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 135 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 136 0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 137 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 138 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 139 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 140 0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 141 0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 142 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 143 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 144 0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 145 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 146 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 147 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 148 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 149 0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 150 0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 151 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 152 0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 153 0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 154 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 155 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 156 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 157 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 158 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 159 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 160 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 161 0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 162 0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 163 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 164 0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 165 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 166 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 167 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 168 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 169 0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 170 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 171 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 172 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 173 0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 174 0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 175 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 176 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 177 0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 178 0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 179 0.472 0.5266389 0.3321321 0.9849038 1.0000000
#&gt; 180 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 181 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 182 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 183 0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 184 0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 185 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 186 0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 187 0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 188 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 189 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 190 0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 191 0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 192 0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 193 0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 194 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 195 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 196 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 197 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 198 0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 199 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 200 0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 201 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 202 0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 203 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 204 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 205 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 206 0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 207 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 208 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 209 0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 210 0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 211 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 212 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 213 0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 214 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 215 0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 216 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 217 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 218 0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 219 0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 220 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 221 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 222 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 223 0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 224 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 225 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 226 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 227 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 228 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 229 0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 230 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 231 0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 232 0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 233 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 234 0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 235 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 236 0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 237 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 238 0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 239 0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 240 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 241 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 242 0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 243 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 244 0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 245 0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 246 0.472 0.0000000 0.0000000 0.0000000 0.0000000
#&gt; 247 0.472 0.3621642 0.1101678 0.1018392 0.1017197
#&gt; 248 0.472 1.0000000 0.9932072 0.9907040 0.9905905
#&gt; 249 0.472 0.5936039 0.8712494 0.8796076 0.8794614
#&gt; 250 0.472 1.0000000 0.9932072 0.9907040 0.9905905</div><div class='input'><span class='no'>modpls.B2</span>$<span class='no'>MissClassed</span></div><div class='output co'>#&gt;      [,1] [,2] [,3] [,4] [,5]
#&gt; [1,]  118   11   13   11   11</div><div class='input'><span class='fu'>plsR</span>(<span class='no'>simbin1</span>$<span class='no'>Y</span>,<span class='no'>dataAstar2</span>[,-<span class='fl'>1</span>],<span class='fl'>10</span>,<span class='kw'>typeVC</span><span class='kw'>=</span><span class='st'>"standard"</span>,<span class='kw'>MClassed</span><span class='kw'>=</span><span class='fl'>TRUE</span>,<span class='kw'>verbose</span><span class='kw'>=</span><span class='fl'>FALSE</span>)$<span class='no'>InfCrit</span></div><div class='output co'>#&gt;                 AIC     Q2cum_Y LimQ2_Y        Q2_Y  PRESS_Y    RSS_Y      R2_Y
#&gt; Nb_Comp_0  366.1104          NA      NA          NA       NA 62.30400        NA
#&gt; Nb_Comp_1  189.5912  0.50491535  0.0975  0.50491535 30.84575 30.50677 0.5103561
#&gt; Nb_Comp_2  131.5243  0.60796629  0.0975  0.20814812 24.15684 23.99105 0.6149356
#&gt; Nb_Comp_3  113.8665  0.58395266  0.0975 -0.06125399 25.46060 22.17687 0.6440539
#&gt; Nb_Comp_4  111.8644  0.51506070  0.0975 -0.16558684 25.84907 21.82468 0.6497066
#&gt; Nb_Comp_5  113.0416  0.43928533  0.0975 -0.15625743 25.23494 21.75297 0.6508576
#&gt; Nb_Comp_6  114.9588  0.35571640  0.0975 -0.14904004 24.99503 21.74577 0.6509731
#&gt; Nb_Comp_7  116.9405  0.26307104  0.0975 -0.14379593 24.87272 21.74418 0.6509987
#&gt; Nb_Comp_8  118.9392  0.16490940  0.0975 -0.13320366 24.64058 21.74406 0.6510005
#&gt; Nb_Comp_9  120.9391  0.05975865  0.0975 -0.12591538 24.48197 21.74405 0.6510007
#&gt; Nb_Comp_10 122.9391 -0.05217258  0.0975 -0.11904521 24.33258 21.74405 0.6510007
#&gt;            MissClassed R2_residY RSS_residY PRESS_residY   Q2_residY  LimQ2
#&gt; Nb_Comp_0          118        NA  249.00000           NA          NA     NA
#&gt; Nb_Comp_1           34 0.5103561  121.92132    123.27608  0.50491535 0.0975
#&gt; Nb_Comp_2            2 0.6149356   95.88103     96.54363  0.20814812 0.0975
#&gt; Nb_Comp_3            7 0.6440539   88.63059    101.75413 -0.06125399 0.0975
#&gt; Nb_Comp_4            8 0.6497066   87.22304    103.30665 -0.16558684 0.0975
#&gt; Nb_Comp_5           10 0.6508576   86.93645    100.85229 -0.15625743 0.0975
#&gt; Nb_Comp_6           10 0.6509731   86.90769     99.89346 -0.14904004 0.0975
#&gt; Nb_Comp_7           10 0.6509987   86.90132     99.40466 -0.14379593 0.0975
#&gt; Nb_Comp_8           10 0.6510005   86.90086     98.47690 -0.13320366 0.0975
#&gt; Nb_Comp_9           10 0.6510007   86.90083     97.84302 -0.12591538 0.0975
#&gt; Nb_Comp_10          10 0.6510007   86.90082     97.24596 -0.11904521 0.0975
#&gt;            Q2cum_residY  AIC.std   DoF.dof sigmahat.dof    AIC.dof   BIC.dof
#&gt; Nb_Comp_0            NA 712.4673  1.000000    0.5002168 0.25121773 0.2547423
#&gt; Nb_Comp_1    0.50491535 535.9480  2.567927    0.3504244 0.12454976 0.1289915
#&gt; Nb_Comp_2    0.60796629 477.8811  3.000065    0.3110275 0.09828597 0.1023740
#&gt; Nb_Comp_3    0.58395266 460.2233 20.983510    0.3105065 0.10489235 0.1333896
#&gt; Nb_Comp_4    0.51506070 458.2212 22.334323    0.3089395 0.10435205 0.1343784
#&gt; Nb_Comp_5    0.43928533 459.3984 22.839929    0.3087731 0.10443249 0.1351055
#&gt; Nb_Comp_6    0.35571640 461.3157 22.843260    0.3087242 0.10440073 0.1350685
#&gt; Nb_Comp_7    0.26307104 463.2973 22.965960    0.3087960 0.10449605 0.1353429
#&gt; Nb_Comp_8    0.16490940 465.2960 22.943206    0.3087798 0.10447640 0.1352894
#&gt; Nb_Comp_9    0.05975865 467.2959 22.997499    0.3088165 0.10452195 0.1354152
#&gt; Nb_Comp_10  -0.05217258 469.2959 23.233596    0.3089765 0.10472044 0.1359633
#&gt;             GMDL.dof DoF.naive sigmahat.naive  AIC.naive  BIC.naive GMDL.naive
#&gt; Nb_Comp_0  -167.7150         1      0.5002168 0.25121773 0.25474225  -167.7150
#&gt; Nb_Comp_1  -252.1687         2      0.3507295 0.12399526 0.12746070  -253.3004
#&gt; Nb_Comp_2  -280.5368         3      0.3116565 0.09829532 0.10239978  -280.0380
#&gt; Nb_Comp_3  -249.1511         4      0.3002497 0.09159227 0.09667162  -286.8595
#&gt; Nb_Comp_4  -248.3530         5      0.2984633 0.09086192 0.09713578  -286.0790
#&gt; Nb_Comp_5  -247.7596         6      0.2985825 0.09129114 0.09882578  -283.8388
#&gt; Nb_Comp_6  -247.7900         7      0.2991467 0.09199445 0.10081812  -281.3230
#&gt; Nb_Comp_7  -247.5661         8      0.2997532 0.09272723 0.10285236  -278.8496
#&gt; Nb_Comp_8  -247.6097         9      0.3003736 0.09347240 0.10491037  -276.4327
#&gt; Nb_Comp_9  -247.5072        10      0.3009987 0.09422423 0.10698604  -274.0730
#&gt; Nb_Comp_10 -247.0619        11      0.3016277 0.09498239 0.10907911  -271.7654</div><div class='input'><span class='no'>cv.modpls.B2</span><span class='kw'>&lt;-</span><span class='fu'><a href='cv.plsR.html'>cv.plsR</a></span>(<span class='no'>Y</span>~<span class='no'>.</span>,<span class='kw'>data</span><span class='kw'>=</span><span class='no'>simbin1</span>,<span class='fl'>2</span>,<span class='kw'>NK</span><span class='kw'>=</span><span class='fl'>100</span>,<span class='kw'>verbose</span><span class='kw'>=</span><span class='fl'>FALSE</span>)
<span class='no'>res.cv.modpls.B2</span><span class='kw'>&lt;-</span><span class='fu'><a href='cvtable.html'>cvtable</a></span>(<span class='fu'><a href='https://www.rdocumentation.org/packages/base/topics/summary'>summary</a></span>(<span class='no'>cv.modpls.B2</span>,<span class='kw'>MClassed</span><span class='kw'>=</span><span class='fl'>TRUE</span>))</div><div class='output co'>#&gt; ____************************************************____</div><div class='output co'>#&gt; <span class='error'>Error in is.data.frame(data): object 'simbin1' not found</span></div><div class='input'><span class='co'>#Only one component found by repeated CV missclassed criterion</span>
<span class='fu'><a href='https://www.rdocumentation.org/packages/graphics/topics/plot'>plot</a></span>(<span class='no'>res.cv.modpls.B2</span>)</div><div class='output co'>#&gt; <span class='error'>Error in plot(res.cv.modpls.B2): object 'res.cv.modpls.B2' not found</span></div><div class='input'>
<span class='fu'><a href='https://www.rdocumentation.org/packages/base/topics/rm'>rm</a></span>(<span class='kw'>list</span><span class='kw'>=</span><span class='fu'><a href='https://www.rdocumentation.org/packages/base/topics/c'>c</a></span>(<span class='st'>"dimX"</span>,<span class='st'>"Astar"</span>,<span class='st'>"dataAstar2"</span>,<span class='st'>"modpls.A2"</span>,<span class='st'>"cv.modpls.A2"</span>,
<span class='st'>"res.cv.modpls.A2"</span>,<span class='st'>"simbin1"</span>,<span class='st'>"modpls.B2"</span>,<span class='st'>"cv.modpls.B2"</span>,<span class='st'>"res.cv.modpls.B2"</span>))</div><div class='output co'>#&gt; <span class='warning'>Warning: object 'res.cv.modpls.A2' not found</span></div><div class='output co'>#&gt; <span class='warning'>Warning: object 'res.cv.modpls.B2' not found</span></div></pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2>Contents</h2>
    <ul class="nav nav-pills nav-stacked">
      <li><a href="#arguments">Arguments</a></li>
      
      <li><a href="#details">Details</a></li>

      <li><a href="#value">Value</a></li>

      <li><a href="#references">References</a></li>

      <li><a href="#note">Note</a></li>

      <li><a href="#see-also">See also</a></li>
      
      <li><a href="#examples">Examples</a></li>
    </ul>

    <h2>Author</h2>
    <p>Frederic Bertrand<br />
<a href='mailto:frederic.bertrand@math.unistra.fr'>frederic.bertrand@math.unistra.fr</a><br />
<a href='http://www-irma.u-strasbg.fr/~fbertran/'>http://www-irma.u-strasbg.fr/~fbertran/</a></p>
  </div>
</div>

      <footer>
      <div class="copyright">
  <p>Developed by Frederic Bertrand, Myriam Maumy-Bertrand.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.3.0.</p>
</div>
      </footer>
   </div>

  

  </body>
</html>

